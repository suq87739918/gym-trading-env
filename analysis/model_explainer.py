"""
å¯è§£é‡Šæ€§åˆ†æå™¨ - åŸºäºSHAPçš„å¼ºåŒ–å­¦ä¹ æ¨¡å‹è§£é‡Š
æä¾›ç‰¹å¾è´¡çŒ®åº¦åˆ†æã€å†³ç­–è§£é‡Šã€å¯è§†åŒ–ç­‰åŠŸèƒ½
"""
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Optional, Any, Callable
import warnings
warnings.filterwarnings('ignore')

import shap
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import plotly.express as px

from utils.config import get_config
from utils.logger import get_logger

class RLModelExplainer:
    """å¼ºåŒ–å­¦ä¹ æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æå™¨"""
    
    def __init__(self, model=None, feature_names: List[str] = None):
        self.config = get_config()
        self.logger = get_logger('ModelExplainer', 'model_explainer.log')
        
        self.model = model
        self.feature_names = feature_names or []
        self.shap_explainer = None
        self.shap_values = None
        self.decision_records = []
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # é…è‰²æ–¹æ¡ˆ
        self.colors = {
            'positive': '#2E8B57',  # æ­£è´¡çŒ®
            'negative': '#DC143C',  # è´Ÿè´¡çŒ®
            'neutral': '#808080',   # ä¸­æ€§
            'action_buy': '#00FF00',
            'action_sell': '#FF0000',
            'action_hold': '#0000FF'
        }
    
    def setup_shap_explainer(self, background_data: np.ndarray, 
                           explainer_type: str = 'permutation') -> bool:
        """
        è®¾ç½®SHAPè§£é‡Šå™¨
        
        Args:
            background_data: èƒŒæ™¯æ•°æ®æ ·æœ¬
            explainer_type: è§£é‡Šå™¨ç±»å‹ ('permutation', 'kernel', 'deep')
        """
        try:
            self.logger.info(f"ğŸ”§ è®¾ç½®SHAPè§£é‡Šå™¨ï¼Œç±»å‹: {explainer_type}")
            
            if explainer_type == 'permutation':
                # å¯¹äºç­–ç•¥ç½‘ç»œï¼Œä½¿ç”¨Permutationè§£é‡Šå™¨
                self.shap_explainer = shap.Explainer(
                    self._model_predict_wrapper, 
                    background_data,
                    feature_names=self.feature_names
                )
            elif explainer_type == 'kernel':
                # Kernelè§£é‡Šå™¨é€‚ç”¨äºä»»ä½•æ¨¡å‹
                self.shap_explainer = shap.KernelExplainer(
                    self._model_predict_wrapper,
                    background_data
                )
            elif explainer_type == 'deep':
                # æ·±åº¦å­¦ä¹ æ¨¡å‹ä¸“ç”¨ï¼ˆéœ€è¦æ¨¡å‹æ”¯æŒï¼‰
                if hasattr(self.model, 'get_layer'):
                    self.shap_explainer = shap.DeepExplainer(
                        self.model, background_data
                    )
                else:
                    self.logger.warning("æ¨¡å‹ä¸æ”¯æŒDeepExplainerï¼Œå›é€€åˆ°Permutation")
                    self.shap_explainer = shap.Explainer(
                        self._model_predict_wrapper, background_data
                    )
            
            self.logger.info("âœ… SHAPè§£é‡Šå™¨è®¾ç½®å®Œæˆ")
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ SHAPè§£é‡Šå™¨è®¾ç½®å¤±è´¥: {e}")
            return False
    
    def _model_predict_wrapper(self, X: np.ndarray) -> np.ndarray:
        """æ¨¡å‹é¢„æµ‹åŒ…è£…å™¨ï¼Œé€‚é…SHAPè¾“å…¥æ ¼å¼"""
        try:
            if hasattr(self.model, 'predict'):
                # æ ‡å‡†æ¨¡å‹é¢„æµ‹æ¥å£
                predictions = self.model.predict(X)
            elif hasattr(self.model, 'forward'):
                # PyTorchæ¨¡å‹
                import torch
                with torch.no_grad():
                    if isinstance(X, np.ndarray):
                        X = torch.FloatTensor(X)
                    predictions = self.model.forward(X).cpu().numpy()
            elif hasattr(self.model, '__call__'):
                # å¯è°ƒç”¨å¯¹è±¡
                predictions = self.model(X)
            else:
                raise ValueError("æ¨¡å‹ä¸æ”¯æŒé¢„æµ‹æ¥å£")
            
            # ç¡®ä¿è¾“å‡ºæ ¼å¼æ­£ç¡®
            if len(predictions.shape) == 1:
                predictions = predictions.reshape(-1, 1)
            
            return predictions
            
        except Exception as e:
            self.logger.error(f"æ¨¡å‹é¢„æµ‹åŒ…è£…å™¨é”™è¯¯: {e}")
            return np.zeros((X.shape[0], 1))
    
    def analyze_single_decision(self, state: np.ndarray, 
                              action_taken: int = None,
                              context_info: Dict = None) -> Dict:
        """
        åˆ†æå•ä¸ªå†³ç­–çš„SHAPå€¼
        
        Args:
            state: å†³ç­–çŠ¶æ€ç‰¹å¾
            action_taken: å®é™…é‡‡å–çš„åŠ¨ä½œ
            context_info: ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆä»·æ ¼ã€æ—¶é—´ç­‰ï¼‰
        
        Returns:
            åŒ…å«SHAPåˆ†æç»“æœçš„å­—å…¸
        """
        try:
            if self.shap_explainer is None:
                self.logger.error("SHAPè§£é‡Šå™¨æœªåˆå§‹åŒ–")
                return {}
            
            # ç¡®ä¿è¾“å…¥æ ¼å¼æ­£ç¡®
            if len(state.shape) == 1:
                state = state.reshape(1, -1)
            
            # è®¡ç®—SHAPå€¼
            shap_values = self.shap_explainer(state)
            
            # æå–ç‰¹å¾è´¡çŒ®
            feature_contributions = {}
            if hasattr(shap_values, 'values'):
                contributions = shap_values.values[0]  # ç¬¬ä¸€ä¸ªæ ·æœ¬
                if len(contributions.shape) > 1:
                    # å¤šè¾“å‡ºæƒ…å†µï¼Œé€‰æ‹©å¯¹åº”åŠ¨ä½œçš„è¾“å‡º
                    if action_taken is not None and action_taken < contributions.shape[1]:
                        contributions = contributions[:, action_taken]
                    else:
                        contributions = contributions[:, 0]  # é»˜è®¤ç¬¬ä¸€ä¸ªè¾“å‡º
                
                for i, contrib in enumerate(contributions):
                    feature_name = self.feature_names[i] if i < len(self.feature_names) else f'feature_{i}'
                    feature_contributions[feature_name] = float(contrib)
            
            # è®¡ç®—åŸºå‡†å€¼
            base_value = float(shap_values.base_values[0]) if hasattr(shap_values, 'base_values') else 0.0
            
            # é¢„æµ‹å€¼
            predicted_value = base_value + sum(feature_contributions.values())
            
            # æ„å»ºåˆ†æç»“æœ
            analysis_result = {
                'timestamp': context_info.get('timestamp') if context_info else None,
                'state_features': state.flatten().tolist(),
                'action_taken': action_taken,
                'predicted_value': predicted_value,
                'base_value': base_value,
                'feature_contributions': feature_contributions,
                'top_positive_features': self._get_top_features(feature_contributions, positive=True),
                'top_negative_features': self._get_top_features(feature_contributions, positive=False),
                'context_info': context_info or {}
            }
            
            # è®°å½•å†³ç­–
            self.decision_records.append(analysis_result)
            
            return analysis_result
            
        except Exception as e:
            self.logger.error(f"å•å†³ç­–SHAPåˆ†æå¤±è´¥: {e}")
            return {}
    
    def analyze_episode_decisions(self, states: np.ndarray, 
                                actions: List[int],
                                context_infos: List[Dict] = None) -> List[Dict]:
        """
        åˆ†ææ•´ä¸ªå›åˆçš„å†³ç­–åºåˆ—
        
        Args:
            states: çŠ¶æ€åºåˆ—
            actions: åŠ¨ä½œåºåˆ—
            context_infos: ä¸Šä¸‹æ–‡ä¿¡æ¯åºåˆ—
        
        Returns:
            å†³ç­–åˆ†æç»“æœåˆ—è¡¨
        """
        try:
            self.logger.info(f"ğŸ“Š åˆ†æå›åˆå†³ç­–åºåˆ—ï¼ŒåŒ…å«{len(states)}ä¸ªå†³ç­–ç‚¹")
            
            results = []
            context_infos = context_infos or [{}] * len(states)
            
            for i, (state, action) in enumerate(zip(states, actions)):
                context = context_infos[i] if i < len(context_infos) else {}
                context['step'] = i
                
                result = self.analyze_single_decision(state, action, context)
                if result:
                    results.append(result)
            
            self.logger.info(f"âœ… å®Œæˆ{len(results)}ä¸ªå†³ç­–ç‚¹çš„åˆ†æ")
            return results
            
        except Exception as e:
            self.logger.error(f"å›åˆå†³ç­–åˆ†æå¤±è´¥: {e}")
            return []
    
    def _get_top_features(self, feature_contributions: Dict, 
                         positive: bool = True, top_k: int = 5) -> List[Tuple[str, float]]:
        """è·å–è´¡çŒ®åº¦æœ€é«˜çš„ç‰¹å¾"""
        filtered_contribs = {
            k: v for k, v in feature_contributions.items() 
            if (v > 0) == positive
        }
        
        sorted_features = sorted(
            filtered_contribs.items(), 
            key=lambda x: abs(x[1]), 
            reverse=True
        )
        
        return sorted_features[:top_k]
    
    def create_decision_explanation_dashboard(self, decision_analysis: Dict,
                                            save_path: str = None) -> str:
        """
        åˆ›å»ºå•ä¸ªå†³ç­–çš„è§£é‡Šçœ‹æ¿
        """
        try:
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=[
                    'ç‰¹å¾è´¡çŒ®åº¦ç€‘å¸ƒå›¾', 'ç‰¹å¾é‡è¦æ€§æ’åº',
                    'æ­£è´Ÿè´¡çŒ®åˆ†å¸ƒ', 'å†³ç­–ä¸Šä¸‹æ–‡ä¿¡æ¯'
                ],
                specs=[
                    [{"type": "waterfall"}, {"type": "bar"}],
                    [{"type": "bar"}, {"type": "table"}]
                ]
            )
            
            # 1. ç€‘å¸ƒå›¾æ˜¾ç¤ºç‰¹å¾è´¡çŒ®è·¯å¾„
            self._add_waterfall_plot(fig, decision_analysis, row=1, col=1)
            
            # 2. ç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾
            self._add_feature_importance_bar(fig, decision_analysis, row=1, col=2)
            
            # 3. æ­£è´Ÿè´¡çŒ®åˆ†å¸ƒ
            self._add_contribution_distribution(fig, decision_analysis, row=2, col=1)
            
            # 4. ä¸Šä¸‹æ–‡ä¿¡æ¯è¡¨æ ¼
            self._add_context_table(fig, decision_analysis, row=2, col=2)
            
            # æ›´æ–°å¸ƒå±€
            action_name = self._get_action_name(decision_analysis.get('action_taken', 0))
            fig.update_layout(
                title=f'å†³ç­–è§£é‡Šåˆ†æ - åŠ¨ä½œ: {action_name}',
                height=800,
                showlegend=True
            )
            
            # ä¿å­˜
            if save_path is None:
                save_path = f"results/decision_explanation.html"
            
            fig.write_html(save_path)
            self.logger.info(f"ğŸ’¾ å†³ç­–è§£é‡Šçœ‹æ¿å·²ä¿å­˜: {save_path}")
            
            return save_path
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºå†³ç­–è§£é‡Šçœ‹æ¿å¤±è´¥: {e}")
            return None
    
    def _add_waterfall_plot(self, fig, decision_analysis: Dict, row: int, col: int):
        """æ·»åŠ ç€‘å¸ƒå›¾"""
        try:
            contributions = decision_analysis.get('feature_contributions', {})
            base_value = decision_analysis.get('base_value', 0)
            
            # å‡†å¤‡ç€‘å¸ƒå›¾æ•°æ®
            features = list(contributions.keys())
            values = list(contributions.values())
            
            # åªæ˜¾ç¤ºè´¡çŒ®åº¦æœ€å¤§çš„å‰10ä¸ªç‰¹å¾
            if len(features) > 10:
                sorted_indices = sorted(range(len(values)), key=lambda i: abs(values[i]), reverse=True)[:10]
                features = [features[i] for i in sorted_indices]
                values = [values[i] for i in sorted_indices]
            
            # åˆ›å»ºç€‘å¸ƒå›¾
            fig.add_trace(
                go.Waterfall(
                    name="ç‰¹å¾è´¡çŒ®",
                    orientation="v",
                    measure=["relative"] * len(features) + ["total"],
                    x=features + ["é¢„æµ‹å€¼"],
                    textposition="outside",
                    text=[f"{v:.3f}" for v in values] + [f"{sum(values) + base_value:.3f}"],
                    y=values + [base_value],
                    connector={"line": {"color": "rgb(63, 63, 63)"}},
                    increasing={"marker": {"color": self.colors['positive']}},
                    decreasing={"marker": {"color": self.colors['negative']}},
                    totals={"marker": {"color": self.colors['neutral']}}
                ),
                row=row, col=col
            )
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ ç€‘å¸ƒå›¾å¤±è´¥: {e}")
    
    def _add_feature_importance_bar(self, fig, decision_analysis: Dict, row: int, col: int):
        """æ·»åŠ ç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾"""
        try:
            contributions = decision_analysis.get('feature_contributions', {})
            
            # æŒ‰ç»å¯¹å€¼æ’åº
            sorted_features = sorted(contributions.items(), key=lambda x: abs(x[1]), reverse=True)[:15]
            features, values = zip(*sorted_features) if sorted_features else ([], [])
            
            # è®¾ç½®é¢œè‰²
            colors = [self.colors['positive'] if v > 0 else self.colors['negative'] for v in values]
            
            fig.add_trace(
                go.Bar(
                    x=list(values),
                    y=list(features),
                    orientation='h',
                    name='ç‰¹å¾è´¡çŒ®',
                    marker_color=colors,
                    text=[f"{v:.3f}" for v in values],
                    textposition='auto'
                ),
                row=row, col=col
            )
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ ç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾å¤±è´¥: {e}")
    
    def _add_contribution_distribution(self, fig, decision_analysis: Dict, row: int, col: int):
        """æ·»åŠ è´¡çŒ®åˆ†å¸ƒå›¾"""
        try:
            contributions = decision_analysis.get('feature_contributions', {})
            values = list(contributions.values())
            
            if not values:
                return
            
            positive_values = [v for v in values if v > 0]
            negative_values = [v for v in values if v < 0]
            
            fig.add_trace(
                go.Bar(
                    x=['æ­£è´¡çŒ®', 'è´Ÿè´¡çŒ®'],
                    y=[sum(positive_values), abs(sum(negative_values))],
                    name='è´¡çŒ®æ±‡æ€»',
                    marker_color=[self.colors['positive'], self.colors['negative']],
                    text=[f"{sum(positive_values):.3f}", f"{sum(negative_values):.3f}"],
                    textposition='auto'
                ),
                row=row, col=col
            )
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ è´¡çŒ®åˆ†å¸ƒå›¾å¤±è´¥: {e}")
    
    def _add_context_table(self, fig, decision_analysis: Dict, row: int, col: int):
        """æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯è¡¨æ ¼"""
        try:
            context = decision_analysis.get('context_info', {})
            
            # å‡†å¤‡è¡¨æ ¼æ•°æ®
            headers = ['ä¿¡æ¯ç±»å‹', 'å€¼']
            cells = []
            
            # åŸºæœ¬ä¿¡æ¯
            cells.append(['åŠ¨ä½œ', self._get_action_name(decision_analysis.get('action_taken', 0))])
            cells.append(['é¢„æµ‹å€¼', f"{decision_analysis.get('predicted_value', 0):.4f}"])
            cells.append(['åŸºå‡†å€¼', f"{decision_analysis.get('base_value', 0):.4f}"])
            
            # ä¸Šä¸‹æ–‡ä¿¡æ¯
            for key, value in context.items():
                if isinstance(value, (int, float)):
                    cells.append([str(key), f"{value:.4f}"])
                else:
                    cells.append([str(key), str(value)])
            
            # è½¬ç½®æ•°æ®
            if cells:
                cell_values = list(zip(*cells))
                
                fig.add_trace(
                    go.Table(
                        header=dict(values=headers, fill_color='lightgray'),
                        cells=dict(values=cell_values, align='left')
                    ),
                    row=row, col=col
                )
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ ä¸Šä¸‹æ–‡è¡¨æ ¼å¤±è´¥: {e}")
    
    def _get_action_name(self, action: int) -> str:
        """è·å–åŠ¨ä½œåç§°"""
        action_names = {0: 'æŒæœ‰', 1: 'å¼€å¤š', 2: 'å¼€ç©º', 3: 'å¹³ä»“'}
        return action_names.get(action, f'åŠ¨ä½œ{action}')
    
    def create_episode_summary_report(self, episode_results: List[Dict],
                                    save_path: str = None) -> str:
        """
        åˆ›å»ºå›åˆæ±‡æ€»åˆ†ææŠ¥å‘Š
        """
        try:
            fig = make_subplots(
                rows=3, cols=2,
                subplot_titles=[
                    'å†³ç­–æ—¶åºåˆ†æ', 'ç‰¹å¾è´¡çŒ®åº¦è¶‹åŠ¿',
                    'åŠ¨ä½œåˆ†å¸ƒç»Ÿè®¡', 'Topç‰¹å¾é‡è¦æ€§',
                    'å†³ç­–ç½®ä¿¡åº¦åˆ†æ', 'å…³é”®å†³ç­–ç‚¹æ ‡æ³¨'
                ],
                specs=[
                    [{"secondary_y": True}, {"type": "scatter"}],
                    [{"type": "pie"}, {"type": "bar"}],
                    [{"type": "box"}, {"secondary_y": True}]
                ]
            )
            
            # 1. å†³ç­–æ—¶åºåˆ†æ
            self._add_decision_timeline(fig, episode_results, row=1, col=1)
            
            # 2. ç‰¹å¾è´¡çŒ®åº¦è¶‹åŠ¿
            self._add_feature_contribution_trends(fig, episode_results, row=1, col=2)
            
            # 3. åŠ¨ä½œåˆ†å¸ƒç»Ÿè®¡
            self._add_action_distribution(fig, episode_results, row=2, col=1)
            
            # 4. Topç‰¹å¾é‡è¦æ€§
            self._add_top_features_summary(fig, episode_results, row=2, col=2)
            
            # 5. å†³ç­–ç½®ä¿¡åº¦åˆ†æ
            self._add_confidence_analysis(fig, episode_results, row=3, col=1)
            
            # 6. å…³é”®å†³ç­–ç‚¹
            self._add_key_decisions(fig, episode_results, row=3, col=2)
            
            fig.update_layout(
                title='å¼ºåŒ–å­¦ä¹ ç­–ç•¥å†³ç­–è§£é‡Š - å›åˆæ±‡æ€»æŠ¥å‘Š',
                height=1200,
                showlegend=True
            )
            
            if save_path is None:
                save_path = f"results/episode_explanation_report.html"
            
            fig.write_html(save_path)
            self.logger.info(f"ğŸ’¾ å›åˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜: {save_path}")
            
            return save_path
            
        except Exception as e:
            self.logger.error(f"åˆ›å»ºå›åˆæ±‡æ€»æŠ¥å‘Šå¤±è´¥: {e}")
            return None
    
    def _add_decision_timeline(self, fig, episode_results: List[Dict], row: int, col: int):
        """æ·»åŠ å†³ç­–æ—¶åºåˆ†æ"""
        try:
            steps = [r.get('context_info', {}).get('step', i) for i, r in enumerate(episode_results)]
            actions = [r.get('action_taken', 0) for r in episode_results]
            predicted_values = [r.get('predicted_value', 0) for r in episode_results]
            
            # åŠ¨ä½œåºåˆ—
            fig.add_trace(
                go.Scatter(
                    x=steps,
                    y=actions,
                    mode='markers+lines',
                    name='åŠ¨ä½œåºåˆ—',
                    marker=dict(size=8),
                    line=dict(width=2)
                ),
                row=row, col=col
            )
            
            # é¢„æµ‹å€¼åºåˆ—ï¼ˆè¾…åŠ©yè½´ï¼‰
            fig.add_trace(
                go.Scatter(
                    x=steps,
                    y=predicted_values,
                    mode='lines',
                    name='é¢„æµ‹å€¼',
                    line=dict(dash='dash'),
                    yaxis='y2'
                ),
                row=row, col=col, secondary_y=True
            )
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ å†³ç­–æ—¶åºåˆ†æå¤±è´¥: {e}")
    
    def _add_feature_contribution_trends(self, fig, episode_results: List[Dict], row: int, col: int):
        """æ·»åŠ ç‰¹å¾è´¡çŒ®åº¦è¶‹åŠ¿"""
        try:
            # æå–ä¸»è¦ç‰¹å¾çš„è´¡çŒ®åº¦å˜åŒ–
            all_features = set()
            for result in episode_results:
                all_features.update(result.get('feature_contributions', {}).keys())
            
            # é€‰æ‹©è´¡çŒ®åº¦æœ€å¤§çš„å‰5ä¸ªç‰¹å¾
            feature_importance = {}
            for feature in all_features:
                total_contrib = sum(abs(r.get('feature_contributions', {}).get(feature, 0)) 
                                  for r in episode_results)
                feature_importance[feature] = total_contrib
            
            top_features = sorted(feature_importance.items(), key=lambda x: x[1], reverse=True)[:5]
            
            steps = list(range(len(episode_results)))
            
            for feature_name, _ in top_features:
                contributions = [r.get('feature_contributions', {}).get(feature_name, 0) 
                               for r in episode_results]
                
                fig.add_trace(
                    go.Scatter(
                        x=steps,
                        y=contributions,
                        mode='lines',
                        name=f'{feature_name}',
                        line=dict(width=2)
                    ),
                    row=row, col=col
                )
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ ç‰¹å¾è´¡çŒ®åº¦è¶‹åŠ¿å¤±è´¥: {e}")
    
    def _add_action_distribution(self, fig, episode_results: List[Dict], row: int, col: int):
        """æ·»åŠ åŠ¨ä½œåˆ†å¸ƒé¥¼å›¾"""
        try:
            actions = [r.get('action_taken', 0) for r in episode_results]
            action_counts = {}
            
            for action in actions:
                action_name = self._get_action_name(action)
                action_counts[action_name] = action_counts.get(action_name, 0) + 1
            
            fig.add_trace(
                go.Pie(
                    labels=list(action_counts.keys()),
                    values=list(action_counts.values()),
                    name='åŠ¨ä½œåˆ†å¸ƒ'
                ),
                row=row, col=col
            )
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ åŠ¨ä½œåˆ†å¸ƒå¤±è´¥: {e}")
    
    def _add_top_features_summary(self, fig, episode_results: List[Dict], row: int, col: int):
        """æ·»åŠ Topç‰¹å¾æ±‡æ€»"""
        try:
            # è®¡ç®—æ‰€æœ‰ç‰¹å¾çš„å¹³å‡ç»å¯¹è´¡çŒ®åº¦
            feature_contributions = {}
            
            for result in episode_results:
                for feature, contrib in result.get('feature_contributions', {}).items():
                    if feature not in feature_contributions:
                        feature_contributions[feature] = []
                    feature_contributions[feature].append(abs(contrib))
            
            # è®¡ç®—å¹³å‡å€¼å¹¶æ’åº
            avg_contributions = {
                feature: np.mean(contribs) 
                for feature, contribs in feature_contributions.items()
            }
            
            top_features = sorted(avg_contributions.items(), key=lambda x: x[1], reverse=True)[:10]
            features, values = zip(*top_features) if top_features else ([], [])
            
            fig.add_trace(
                go.Bar(
                    x=list(values),
                    y=list(features),
                    orientation='h',
                    name='å¹³å‡è´¡çŒ®åº¦',
                    marker_color=self.colors['positive']
                ),
                row=row, col=col
            )
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ Topç‰¹å¾æ±‡æ€»å¤±è´¥: {e}")
    
    def _add_confidence_analysis(self, fig, episode_results: List[Dict], row: int, col: int):
        """æ·»åŠ å†³ç­–ç½®ä¿¡åº¦åˆ†æ"""
        try:
            # åŸºäºé¢„æµ‹å€¼çš„åˆ†å¸ƒåˆ†æå†³ç­–ç½®ä¿¡åº¦
            predicted_values = [r.get('predicted_value', 0) for r in episode_results]
            actions = [r.get('action_taken', 0) for r in episode_results]
            
            action_groups = {}
            for action, pred_val in zip(actions, predicted_values):
                action_name = self._get_action_name(action)
                if action_name not in action_groups:
                    action_groups[action_name] = []
                action_groups[action_name].append(pred_val)
            
            for action_name, values in action_groups.items():
                fig.add_trace(
                    go.Box(
                        y=values,
                        name=action_name,
                        boxpoints='outliers'
                    ),
                    row=row, col=col
                )
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ ç½®ä¿¡åº¦åˆ†æå¤±è´¥: {e}")
    
    def _add_key_decisions(self, fig, episode_results: List[Dict], row: int, col: int):
        """æ·»åŠ å…³é”®å†³ç­–ç‚¹åˆ†æ"""
        try:
            # æ‰¾å‡ºè´¡çŒ®åº¦æœ€å¤§çš„å†³ç­–ç‚¹
            steps = []
            total_contributions = []
            
            for i, result in enumerate(episode_results):
                contributions = result.get('feature_contributions', {})
                total_contrib = sum(abs(v) for v in contributions.values())
                
                steps.append(i)
                total_contributions.append(total_contrib)
            
            # æ ‡è®°å…³é”®å†³ç­–ç‚¹ï¼ˆè´¡çŒ®åº¦æœ€å¤§çš„å‰20%ï¼‰
            threshold = np.percentile(total_contributions, 80) if total_contributions else 0
            key_steps = [s for s, c in zip(steps, total_contributions) if c >= threshold]
            key_contributions = [c for c in total_contributions if c >= threshold]
            
            # æ€»è´¡çŒ®åº¦æ›²çº¿
            fig.add_trace(
                go.Scatter(
                    x=steps,
                    y=total_contributions,
                    mode='lines',
                    name='æ€»è´¡çŒ®åº¦',
                    line=dict(color='blue', width=2)
                ),
                row=row, col=col
            )
            
            # å…³é”®å†³ç­–ç‚¹
            fig.add_trace(
                go.Scatter(
                    x=key_steps,
                    y=key_contributions,
                    mode='markers',
                    name='å…³é”®å†³ç­–ç‚¹',
                    marker=dict(
                        size=10,
                        color='red',
                        symbol='star'
                    )
                ),
                row=row, col=col
            )
            
        except Exception as e:
            self.logger.error(f"æ·»åŠ å…³é”®å†³ç­–ç‚¹åˆ†æå¤±è´¥: {e}")
    
    def get_explainability_summary(self) -> Dict:
        """è·å–å¯è§£é‡Šæ€§åˆ†ææ‘˜è¦"""
        try:
            if not self.decision_records:
                return {"error": "æ— å†³ç­–è®°å½•å¯åˆ†æ"}
            
            # è®¡ç®—æ€»ä½“ç»Ÿè®¡
            all_contributions = {}
            action_distribution = {}
            
            for record in self.decision_records:
                # ç‰¹å¾è´¡çŒ®ç»Ÿè®¡
                for feature, contrib in record.get('feature_contributions', {}).items():
                    if feature not in all_contributions:
                        all_contributions[feature] = []
                    all_contributions[feature].append(abs(contrib))
                
                # åŠ¨ä½œåˆ†å¸ƒç»Ÿè®¡
                action = record.get('action_taken', 0)
                action_name = self._get_action_name(action)
                action_distribution[action_name] = action_distribution.get(action_name, 0) + 1
            
            # è®¡ç®—ç‰¹å¾é‡è¦æ€§æ’åº
            feature_importance = {
                feature: {
                    'avg_contribution': np.mean(contribs),
                    'max_contribution': np.max(contribs),
                    'std_contribution': np.std(contribs),
                    'frequency': len(contribs)
                }
                for feature, contribs in all_contributions.items()
            }
            
            # æ’åº
            sorted_features = sorted(
                feature_importance.items(),
                key=lambda x: x[1]['avg_contribution'],
                reverse=True
            )
            
            summary = {
                'total_decisions_analyzed': len(self.decision_records),
                'action_distribution': action_distribution,
                'top_10_features': {
                    feature: stats for feature, stats in sorted_features[:10]
                },
                'feature_importance_ranking': [feature for feature, _ in sorted_features],
                'analysis_coverage': {
                    'features_analyzed': len(all_contributions),
                    'avg_features_per_decision': np.mean([
                        len(r.get('feature_contributions', {})) for r in self.decision_records
                    ]),
                    'decisions_with_explanations': len([
                        r for r in self.decision_records if r.get('feature_contributions')
                    ])
                }
            }
            
            return summary
            
        except Exception as e:
            self.logger.error(f"ç”Ÿæˆå¯è§£é‡Šæ€§æ‘˜è¦å¤±è´¥: {e}")
            return {"error": str(e)}

def main():
    """æµ‹è¯•å¯è§£é‡Šæ€§åˆ†æå™¨åŠŸèƒ½"""
    print("ğŸ” æµ‹è¯•å¼ºåŒ–å­¦ä¹ æ¨¡å‹å¯è§£é‡Šæ€§åˆ†æå™¨")
    
    explainer = RLModelExplainer()
    print("âœ… å¯è§£é‡Šæ€§åˆ†æå™¨åˆå§‹åŒ–å®Œæˆ")
    print("ğŸ“‹ ä¸»è¦åŠŸèƒ½:")
    print("  - SHAPå€¼ç‰¹å¾è´¡çŒ®åˆ†æ")
    print("  - å•å†³ç­–æ·±åº¦è§£é‡Š")
    print("  - å›åˆå†³ç­–åºåˆ—åˆ†æ")
    print("  - å¯è§†åŒ–è§£é‡Šçœ‹æ¿")
    print("  - å†³ç­–è§„å¾‹å‘ç°")

if __name__ == "__main__":
    main() 