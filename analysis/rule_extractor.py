"""
ç­–ç•¥è§„åˆ™æå–å™¨
ä»è®­ç»ƒå¥½çš„å¼ºåŒ–å­¦ä¹ æ¨¡å‹ä¸­æå–å¯è§£é‡Šçš„äº¤æ˜“è§„åˆ™
æ”¯æŒå†³ç­–æ ‘ã€è§„åˆ™é›†åˆã€é€»è¾‘å›å½’ç­‰æ–¹æ³•
"""
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional, Any
import warnings
warnings.filterwarnings('ignore')

from sklearn.tree import DecisionTreeClassifier, export_text
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
import matplotlib.pyplot as plt
import seaborn as sns
import graphviz
from sklearn.tree import export_graphviz

from utils.config import get_config
from utils.logger import get_logger

class TradingRuleExtractor:
    """äº¤æ˜“è§„åˆ™æå–å™¨"""
    
    def __init__(self, feature_names: List[str] = None):
        self.config = get_config()
        self.logger = get_logger('RuleExtractor', 'rule_extractor.log')
        
        self.feature_names = feature_names or []
        self.extracted_rules = {}
        self.surrogate_models = {}
        self.training_data = None
        
        # è®¾ç½®ä¸­æ–‡å­—ä½“
        plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
    
    def collect_policy_data(self, model, states: np.ndarray, 
                          context_info: List[Dict] = None) -> Tuple[np.ndarray, np.ndarray]:
        """
        æ”¶é›†ç­–ç•¥å†³ç­–æ•°æ®
        
        Args:
            model: è®­ç»ƒå¥½çš„å¼ºåŒ–å­¦ä¹ æ¨¡å‹
            states: çŠ¶æ€æ•°ç»„
            context_info: ä¸Šä¸‹æ–‡ä¿¡æ¯
        
        Returns:
            (states, actions): çŠ¶æ€å’Œå¯¹åº”çš„åŠ¨ä½œ
        """
        try:
            self.logger.info(f"ğŸ“Š æ”¶é›†ç­–ç•¥æ•°æ®ï¼ŒçŠ¶æ€æ•°é‡: {len(states)}")
            
            actions = []
            
            for i, state in enumerate(states):
                try:
                    # ä½¿ç”¨æ¨¡å‹é¢„æµ‹åŠ¨ä½œ
                    if hasattr(model, 'predict'):
                        action, _ = model.predict(state.reshape(1, -1), deterministic=True)
                        actions.append(action[0])
                    elif hasattr(model, 'forward'):
                        # PyTorchæ¨¡å‹
                        import torch
                        with torch.no_grad():
                            if isinstance(state, np.ndarray):
                                state_tensor = torch.FloatTensor(state.reshape(1, -1))
                            else:
                                state_tensor = state
                            action_probs = model.forward(state_tensor)
                            action = torch.argmax(action_probs, dim=-1).item()
                            actions.append(action)
                    else:
                        # ç›´æ¥è°ƒç”¨
                        action = model(state.reshape(1, -1))
                        actions.append(int(action))
                        
                except Exception as e:
                    self.logger.warning(f"çŠ¶æ€{i}é¢„æµ‹å¤±è´¥: {e}")
                    actions.append(0)  # é»˜è®¤åŠ¨ä½œ
            
            actions = np.array(actions)
            
            # å­˜å‚¨è®­ç»ƒæ•°æ®
            self.training_data = {
                'states': states,
                'actions': actions,
                'context_info': context_info or [{}] * len(states)
            }
            
            self.logger.info(f"âœ… æ”¶é›†å®Œæˆï¼Œè·å¾—{len(actions)}ä¸ªå†³ç­–æ ·æœ¬")
            self.logger.info(f"ğŸ“ˆ åŠ¨ä½œåˆ†å¸ƒ: {np.bincount(actions)}")
            
            return states, actions
            
        except Exception as e:
            self.logger.error(f"âŒ ç­–ç•¥æ•°æ®æ”¶é›†å¤±è´¥: {e}")
            return np.array([]), np.array([])
    
    def extract_decision_tree_rules(self, states: np.ndarray, actions: np.ndarray,
                                  max_depth: int = 10, min_samples_leaf: int = 20) -> Dict:
        """
        ä½¿ç”¨å†³ç­–æ ‘æå–è§„åˆ™
        
        Args:
            states: çŠ¶æ€ç‰¹å¾
            actions: å¯¹åº”åŠ¨ä½œ
            max_depth: æœ€å¤§æ·±åº¦
            min_samples_leaf: å¶å­èŠ‚ç‚¹æœ€å°æ ·æœ¬æ•°
        
        Returns:
            è§„åˆ™æå–ç»“æœ
        """
        try:
            self.logger.info("ğŸŒ² ä½¿ç”¨å†³ç­–æ ‘æå–äº¤æ˜“è§„åˆ™...")
            
            # è®­ç»ƒå†³ç­–æ ‘
            dt_model = DecisionTreeClassifier(
                max_depth=max_depth,
                min_samples_leaf=min_samples_leaf,
                random_state=42,
                class_weight='balanced'
            )
            
            dt_model.fit(states, actions)
            
            # é¢„æµ‹å‡†ç¡®ç‡
            predictions = dt_model.predict(states)
            accuracy = accuracy_score(actions, predictions)
            
            # æå–æ–‡æœ¬è§„åˆ™
            tree_rules = export_text(
                dt_model, 
                feature_names=self.feature_names[:states.shape[1]] if self.feature_names else None,
                class_names=[f'Action_{i}' for i in range(len(np.unique(actions)))]
            )
            
            # ç‰¹å¾é‡è¦æ€§
            feature_importance = dict(zip(
                self.feature_names[:states.shape[1]] if self.feature_names else [f'feature_{i}' for i in range(states.shape[1])],
                dt_model.feature_importances_
            ))
            
            # è§£æè§„åˆ™ä¸ºå¯è¯»æ ¼å¼
            readable_rules = self._parse_decision_tree_rules(dt_model, states, actions)
            
            result = {
                'model': dt_model,
                'accuracy': accuracy,
                'tree_rules_text': tree_rules,
                'feature_importance': feature_importance,
                'readable_rules': readable_rules,
                'classification_report': classification_report(actions, predictions, output_dict=True)
            }
            
            self.extracted_rules['decision_tree'] = result
            self.surrogate_models['decision_tree'] = dt_model
            
            self.logger.info(f"âœ… å†³ç­–æ ‘è§„åˆ™æå–å®Œæˆï¼Œå‡†ç¡®ç‡: {accuracy:.3f}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ å†³ç­–æ ‘è§„åˆ™æå–å¤±è´¥: {e}")
            return {}
    
    def extract_random_forest_rules(self, states: np.ndarray, actions: np.ndarray,
                                   n_trees: int = 50, max_depth: int = 8) -> Dict:
        """
        ä½¿ç”¨éšæœºæ£®æ—æå–è§„åˆ™
        
        Args:
            states: çŠ¶æ€ç‰¹å¾
            actions: å¯¹åº”åŠ¨ä½œ
            n_trees: æ ‘çš„æ•°é‡
            max_depth: æœ€å¤§æ·±åº¦
        
        Returns:
            è§„åˆ™æå–ç»“æœ
        """
        try:
            self.logger.info("ğŸŒ³ ä½¿ç”¨éšæœºæ£®æ—æå–äº¤æ˜“è§„åˆ™...")
            
            # è®­ç»ƒéšæœºæ£®æ—
            rf_model = RandomForestClassifier(
                n_estimators=n_trees,
                max_depth=max_depth,
                min_samples_leaf=10,
                random_state=42,
                class_weight='balanced'
            )
            
            rf_model.fit(states, actions)
            
            # é¢„æµ‹å‡†ç¡®ç‡
            predictions = rf_model.predict(states)
            accuracy = accuracy_score(actions, predictions)
            
            # ç‰¹å¾é‡è¦æ€§
            feature_importance = dict(zip(
                self.feature_names[:states.shape[1]] if self.feature_names else [f'feature_{i}' for i in range(states.shape[1])],
                rf_model.feature_importances_
            ))
            
            # æå–æœ€é‡è¦çš„å‡ æ£µæ ‘çš„è§„åˆ™
            important_trees_rules = []
            tree_importances = []
            
            for i, tree in enumerate(rf_model.estimators_[:5]):  # åªåˆ†æå‰5æ£µæ ‘
                tree_rules = export_text(
                    tree,
                    feature_names=self.feature_names[:states.shape[1]] if self.feature_names else None
                )
                
                # è®¡ç®—æ ‘çš„é‡è¦æ€§ï¼ˆåŸºäºå‡†ç¡®ç‡ï¼‰
                tree_pred = tree.predict(states)
                tree_acc = accuracy_score(actions, tree_pred)
                
                important_trees_rules.append({
                    'tree_index': i,
                    'accuracy': tree_acc,
                    'rules': tree_rules
                })
                tree_importances.append(tree_acc)
            
            # æ’åºé€‰æ‹©æœ€å¥½çš„æ ‘
            important_trees_rules.sort(key=lambda x: x['accuracy'], reverse=True)
            
            result = {
                'model': rf_model,
                'accuracy': accuracy,
                'feature_importance': feature_importance,
                'important_trees': important_trees_rules[:3],  # å‰3æ£µæœ€å¥½çš„æ ‘
                'classification_report': classification_report(actions, predictions, output_dict=True)
            }
            
            self.extracted_rules['random_forest'] = result
            self.surrogate_models['random_forest'] = rf_model
            
            self.logger.info(f"âœ… éšæœºæ£®æ—è§„åˆ™æå–å®Œæˆï¼Œå‡†ç¡®ç‡: {accuracy:.3f}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ éšæœºæ£®æ—è§„åˆ™æå–å¤±è´¥: {e}")
            return {}
    
    def extract_logistic_regression_rules(self, states: np.ndarray, actions: np.ndarray) -> Dict:
        """
        ä½¿ç”¨é€»è¾‘å›å½’æå–çº¿æ€§è§„åˆ™
        
        Args:
            states: çŠ¶æ€ç‰¹å¾
            actions: å¯¹åº”åŠ¨ä½œ
        
        Returns:
            è§„åˆ™æå–ç»“æœ
        """
        try:
            self.logger.info("ğŸ“ˆ ä½¿ç”¨é€»è¾‘å›å½’æå–çº¿æ€§è§„åˆ™...")
            
            # è®­ç»ƒé€»è¾‘å›å½’
            lr_model = LogisticRegression(
                max_iter=1000,
                random_state=42,
                class_weight='balanced',
                multi_class='ovr'
            )
            
            lr_model.fit(states, actions)
            
            # é¢„æµ‹å‡†ç¡®ç‡
            predictions = lr_model.predict(states)
            accuracy = accuracy_score(actions, predictions)
            
            # è·å–ç³»æ•°
            feature_names_used = self.feature_names[:states.shape[1]] if self.feature_names else [f'feature_{i}' for i in range(states.shape[1])]
            
            # æ¯ä¸ªç±»åˆ«çš„çº¿æ€§è§„åˆ™
            linear_rules = {}
            
            if len(lr_model.classes_) == 2:
                # äºŒåˆ†ç±»
                coefficients = lr_model.coef_[0]
                intercept = lr_model.intercept_[0]
                
                linear_rules[f'Action_{lr_model.classes_[1]}_vs_{lr_model.classes_[0]}'] = {
                    'intercept': intercept,
                    'coefficients': dict(zip(feature_names_used, coefficients)),
                    'equation': self._create_linear_equation(feature_names_used, coefficients, intercept)
                }
            else:
                # å¤šåˆ†ç±»
                for i, class_label in enumerate(lr_model.classes_):
                    coefficients = lr_model.coef_[i]
                    intercept = lr_model.intercept_[i]
                    
                    linear_rules[f'Action_{class_label}'] = {
                        'intercept': intercept,
                        'coefficients': dict(zip(feature_names_used, coefficients)),
                        'equation': self._create_linear_equation(feature_names_used, coefficients, intercept)
                    }
            
            # ç‰¹å¾é‡è¦æ€§ï¼ˆåŸºäºç³»æ•°ç»å¯¹å€¼ï¼‰
            if len(lr_model.classes_) == 2:
                feature_importance = dict(zip(feature_names_used, np.abs(lr_model.coef_[0])))
            else:
                # å¤šåˆ†ç±»ï¼šè®¡ç®—æ‰€æœ‰ç±»åˆ«ç³»æ•°çš„å¹³å‡ç»å¯¹å€¼
                avg_abs_coef = np.mean(np.abs(lr_model.coef_), axis=0)
                feature_importance = dict(zip(feature_names_used, avg_abs_coef))
            
            result = {
                'model': lr_model,
                'accuracy': accuracy,
                'linear_rules': linear_rules,
                'feature_importance': feature_importance,
                'classification_report': classification_report(actions, predictions, output_dict=True)
            }
            
            self.extracted_rules['logistic_regression'] = result
            self.surrogate_models['logistic_regression'] = lr_model
            
            self.logger.info(f"âœ… é€»è¾‘å›å½’è§„åˆ™æå–å®Œæˆï¼Œå‡†ç¡®ç‡: {accuracy:.3f}")
            
            return result
            
        except Exception as e:
            self.logger.error(f"âŒ é€»è¾‘å›å½’è§„åˆ™æå–å¤±è´¥: {e}")
            return {}
    
    def _parse_decision_tree_rules(self, dt_model, states: np.ndarray, actions: np.ndarray) -> List[Dict]:
        """è§£æå†³ç­–æ ‘è§„åˆ™ä¸ºå¯è¯»æ ¼å¼"""
        try:
            tree = dt_model.tree_
            feature_names_used = self.feature_names[:states.shape[1]] if self.feature_names else [f'feature_{i}' for i in range(states.shape[1])]
            
            def extract_rules_recursive(node_id, depth=0, parent_rule=""):
                rules = []
                
                # å¦‚æœæ˜¯å¶å­èŠ‚ç‚¹
                if tree.children_left[node_id] == tree.children_right[node_id]:
                    class_counts = tree.value[node_id][0]
                    predicted_class = np.argmax(class_counts)
                    confidence = class_counts[predicted_class] / np.sum(class_counts)
                    
                    rule = {
                        'conditions': parent_rule,
                        'action': f'Action_{predicted_class}',
                        'confidence': confidence,
                        'samples': int(np.sum(class_counts)),
                        'depth': depth
                    }
                    rules.append(rule)
                else:
                    # å†…éƒ¨èŠ‚ç‚¹
                    feature_idx = tree.feature[node_id]
                    threshold = tree.threshold[node_id]
                    feature_name = feature_names_used[feature_idx] if feature_idx < len(feature_names_used) else f'feature_{feature_idx}'
                    
                    # å·¦å­æ ‘ (<=)
                    left_condition = f"{feature_name} <= {threshold:.3f}"
                    new_parent_rule = f"{parent_rule} AND {left_condition}" if parent_rule else left_condition
                    rules.extend(extract_rules_recursive(tree.children_left[node_id], depth+1, new_parent_rule))
                    
                    # å³å­æ ‘ (>)
                    right_condition = f"{feature_name} > {threshold:.3f}"
                    new_parent_rule = f"{parent_rule} AND {right_condition}" if parent_rule else right_condition
                    rules.extend(extract_rules_recursive(tree.children_right[node_id], depth+1, new_parent_rule))
                
                return rules
            
            return extract_rules_recursive(0)
            
        except Exception as e:
            self.logger.error(f"è§£æå†³ç­–æ ‘è§„åˆ™å¤±è´¥: {e}")
            return []
    
    def _create_linear_equation(self, feature_names: List[str], coefficients: np.ndarray, intercept: float) -> str:
        """åˆ›å»ºçº¿æ€§æ–¹ç¨‹å­—ç¬¦ä¸²"""
        try:
            terms = []
            
            for name, coef in zip(feature_names, coefficients):
                if abs(coef) > 1e-6:  # å¿½ç•¥æå°çš„ç³»æ•°
                    sign = "+" if coef > 0 else "-"
                    if not terms:  # ç¬¬ä¸€é¡¹ä¸éœ€è¦ç¬¦å·
                        terms.append(f"{coef:.3f} * {name}")
                    else:
                        terms.append(f" {sign} {abs(coef):.3f} * {name}")
            
            if intercept != 0:
                sign = "+" if intercept > 0 else "-"
                terms.append(f" {sign} {abs(intercept):.3f}")
            
            equation = "".join(terms)
            return f"score = {equation}"
            
        except Exception as e:
            return f"æ–¹ç¨‹ç”Ÿæˆé”™è¯¯: {e}"
    
    def create_rule_summary_report(self, save_path: str = None) -> str:
        """
        åˆ›å»ºè§„åˆ™æ‘˜è¦æŠ¥å‘Š
        """
        try:
            self.logger.info("ğŸ“‹ åˆ›å»ºè§„åˆ™æ‘˜è¦æŠ¥å‘Š...")
            
            # åˆ›å»ºå›¾å½¢
            fig, axes = plt.subplots(2, 2, figsize=(16, 12))
            fig.suptitle('äº¤æ˜“ç­–ç•¥è§„åˆ™æå–æ‘˜è¦æŠ¥å‘Š', fontsize=16, fontweight='bold')
            
            # 1. æ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”
            if self.extracted_rules:
                model_names = list(self.extracted_rules.keys())
                accuracies = [result['accuracy'] for result in self.extracted_rules.values()]
                
                axes[0, 0].bar(model_names, accuracies, color=['skyblue', 'lightgreen', 'lightcoral'])
                axes[0, 0].set_title('ä»£ç†æ¨¡å‹å‡†ç¡®ç‡å¯¹æ¯”')
                axes[0, 0].set_ylabel('å‡†ç¡®ç‡')
                axes[0, 0].set_ylim([0, 1])
                
                # æ·»åŠ æ•°å€¼æ ‡ç­¾
                for i, acc in enumerate(accuracies):
                    axes[0, 0].text(i, acc + 0.01, f'{acc:.3f}', ha='center')
            
            # 2. ç‰¹å¾é‡è¦æ€§å¯¹æ¯”ï¼ˆå¦‚æœæœ‰å†³ç­–æ ‘ç»“æœï¼‰
            if 'decision_tree' in self.extracted_rules:
                feature_imp = self.extracted_rules['decision_tree']['feature_importance']
                # é€‰æ‹©top10ç‰¹å¾
                top_features = sorted(feature_imp.items(), key=lambda x: x[1], reverse=True)[:10]
                features, importances = zip(*top_features)
                
                axes[0, 1].barh(features, importances, color='orange')
                axes[0, 1].set_title('Top10 ç‰¹å¾é‡è¦æ€§ (å†³ç­–æ ‘)')
                axes[0, 1].set_xlabel('é‡è¦æ€§')
            
            # 3. åŠ¨ä½œåˆ†å¸ƒ
            if self.training_data:
                actions = self.training_data['actions']
                action_counts = np.bincount(actions)
                action_labels = [f'Action_{i}' for i in range(len(action_counts))]
                
                axes[1, 0].pie(action_counts, labels=action_labels, autopct='%1.1f%%')
                axes[1, 0].set_title('ç­–ç•¥åŠ¨ä½œåˆ†å¸ƒ')
            
            # 4. è§„åˆ™å¤æ‚åº¦åˆ†æ
            complexity_data = {}
            if 'decision_tree' in self.extracted_rules:
                dt_model = self.extracted_rules['decision_tree']['model']
                complexity_data['å†³ç­–æ ‘æ·±åº¦'] = dt_model.get_depth()
                complexity_data['å¶å­èŠ‚ç‚¹æ•°'] = dt_model.get_n_leaves()
            
            if 'random_forest' in self.extracted_rules:
                rf_model = self.extracted_rules['random_forest']['model']
                complexity_data['éšæœºæ£®æ—æ ‘æ•°'] = rf_model.n_estimators
                complexity_data['å¹³å‡æ ‘æ·±åº¦'] = np.mean([tree.get_depth() for tree in rf_model.estimators_])
            
            if complexity_data:
                metrics = list(complexity_data.keys())
                values = list(complexity_data.values())
                
                axes[1, 1].bar(metrics, values, color='purple', alpha=0.7)
                axes[1, 1].set_title('è§„åˆ™å¤æ‚åº¦æŒ‡æ ‡')
                axes[1, 1].tick_params(axis='x', rotation=45)
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾ç‰‡
            if save_path is None:
                save_path = "results/rule_extraction_summary.png"
            
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            plt.close()
            
            # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
            text_report = self._generate_text_report()
            text_report_path = save_path.replace('.png', '_text.txt')
            
            with open(text_report_path, 'w', encoding='utf-8') as f:
                f.write(text_report)
            
            self.logger.info(f"âœ… è§„åˆ™æ‘˜è¦æŠ¥å‘Šå·²ä¿å­˜: {save_path}")
            self.logger.info(f"ğŸ“„ æ–‡æœ¬æŠ¥å‘Šå·²ä¿å­˜: {text_report_path}")
            
            return save_path
            
        except Exception as e:
            self.logger.error(f"âŒ åˆ›å»ºè§„åˆ™æ‘˜è¦æŠ¥å‘Šå¤±è´¥: {e}")
            return None
    
    def _generate_text_report(self) -> str:
        """ç”Ÿæˆæ–‡æœ¬æ ¼å¼çš„è¯¦ç»†æŠ¥å‘Š"""
        try:
            report_lines = []
            report_lines.append("=" * 80)
            report_lines.append("äº¤æ˜“ç­–ç•¥è§„åˆ™æå–è¯¦ç»†æŠ¥å‘Š")
            report_lines.append("=" * 80)
            report_lines.append("")
            
            # æ€»ä½“ç»Ÿè®¡
            if self.training_data:
                total_samples = len(self.training_data['actions'])
                unique_actions = len(np.unique(self.training_data['actions']))
                report_lines.append(f"æ•°æ®ç»Ÿè®¡:")
                report_lines.append(f"  æ€»æ ·æœ¬æ•°: {total_samples:,}")
                report_lines.append(f"  åŠ¨ä½œç±»åˆ«æ•°: {unique_actions}")
                report_lines.append(f"  ç‰¹å¾ç»´åº¦: {self.training_data['states'].shape[1]}")
                report_lines.append("")
            
            # å„æ¨¡å‹ç»“æœ
            for model_name, result in self.extracted_rules.items():
                report_lines.append(f"{model_name.upper()} è§„åˆ™æå–ç»“æœ:")
                report_lines.append("-" * 40)
                report_lines.append(f"  å‡†ç¡®ç‡: {result['accuracy']:.4f}")
                
                if 'feature_importance' in result:
                    report_lines.append("  Top5 é‡è¦ç‰¹å¾:")
                    top_features = sorted(result['feature_importance'].items(), 
                                        key=lambda x: x[1], reverse=True)[:5]
                    for feature, importance in top_features:
                        report_lines.append(f"    {feature}: {importance:.4f}")
                
                if model_name == 'decision_tree' and 'readable_rules' in result:
                    report_lines.append("  ä¸»è¦å†³ç­–è§„åˆ™ï¼ˆå‰5æ¡ï¼‰:")
                    rules = result['readable_rules'][:5]
                    for i, rule in enumerate(rules, 1):
                        confidence = rule.get('confidence', 0)
                        samples = rule.get('samples', 0)
                        conditions = rule.get('conditions', '')
                        action = rule.get('action', '')
                        
                        report_lines.append(f"    è§„åˆ™{i}: IF {conditions}")
                        report_lines.append(f"            THEN {action} (ç½®ä¿¡åº¦: {confidence:.3f}, æ ·æœ¬: {samples})")
                
                if model_name == 'logistic_regression' and 'linear_rules' in result:
                    report_lines.append("  çº¿æ€§å†³ç­–æ–¹ç¨‹:")
                    for action, rule_info in result['linear_rules'].items():
                        equation = rule_info.get('equation', '')
                        report_lines.append(f"    {action}: {equation}")
                
                report_lines.append("")
            
            # å»ºè®®å’Œæ€»ç»“
            report_lines.append("è§„åˆ™åˆ†æå»ºè®®:")
            report_lines.append("-" * 40)
            
            if self.extracted_rules:
                # æ‰¾å‡ºæœ€å‡†ç¡®çš„æ¨¡å‹
                best_model = max(self.extracted_rules.items(), key=lambda x: x[1]['accuracy'])
                report_lines.append(f"1. æœ€ä½³ä»£ç†æ¨¡å‹: {best_model[0]} (å‡†ç¡®ç‡: {best_model[1]['accuracy']:.4f})")
                
                # é€šç”¨é‡è¦ç‰¹å¾
                all_features = {}
                for result in self.extracted_rules.values():
                    if 'feature_importance' in result:
                        for feature, importance in result['feature_importance'].items():
                            if feature not in all_features:
                                all_features[feature] = []
                            all_features[feature].append(importance)
                
                if all_features:
                    avg_importance = {f: np.mean(imps) for f, imps in all_features.items()}
                    top_common_features = sorted(avg_importance.items(), key=lambda x: x[1], reverse=True)[:3]
                    
                    report_lines.append("2. æœ€é‡è¦çš„é€šç”¨ç‰¹å¾:")
                    for feature, avg_imp in top_common_features:
                        report_lines.append(f"   - {feature}: å¹³å‡é‡è¦æ€§ {avg_imp:.4f}")
                
                report_lines.append("3. ç­–ç•¥è§£é‡Šå»ºè®®:")
                report_lines.append("   - å¯ä»¥æ ¹æ®æå–çš„è§„åˆ™éªŒè¯ç­–ç•¥é€»è¾‘çš„åˆç†æ€§")
                report_lines.append("   - å…³æ³¨é«˜é‡è¦æ€§ç‰¹å¾çš„é˜ˆå€¼è®¾å®š")
                report_lines.append("   - è€ƒè™‘å°†å¤æ‚è§„åˆ™ç®€åŒ–ä¸ºäººå·¥å¯æ‰§è¡Œçš„ç­–ç•¥")
            
            report_lines.append("")
            report_lines.append("=" * 80)
            
            return "\n".join(report_lines)
            
        except Exception as e:
            return f"æŠ¥å‘Šç”Ÿæˆé”™è¯¯: {e}"
    
    def get_trading_strategy_summary(self) -> Dict:
        """è·å–äº¤æ˜“ç­–ç•¥æ‘˜è¦"""
        try:
            if not self.extracted_rules:
                return {"error": "æ²¡æœ‰æå–çš„è§„åˆ™å¯åˆ†æ"}
            
            summary = {
                'models_trained': list(self.extracted_rules.keys()),
                'best_model': None,
                'model_accuracies': {},
                'common_important_features': [],
                'strategy_insights': []
            }
            
            # æ¨¡å‹å‡†ç¡®ç‡
            for model_name, result in self.extracted_rules.items():
                summary['model_accuracies'][model_name] = result['accuracy']
            
            # æœ€ä½³æ¨¡å‹
            if summary['model_accuracies']:
                best_model_name = max(summary['model_accuracies'].items(), key=lambda x: x[1])[0]
                summary['best_model'] = {
                    'name': best_model_name,
                    'accuracy': summary['model_accuracies'][best_model_name],
                    'details': self.extracted_rules[best_model_name]
                }
            
            # é€šç”¨é‡è¦ç‰¹å¾
            all_features = {}
            for result in self.extracted_rules.values():
                if 'feature_importance' in result:
                    for feature, importance in result['feature_importance'].items():
                        if feature not in all_features:
                            all_features[feature] = []
                        all_features[feature].append(importance)
            
            if all_features:
                avg_importance = {f: np.mean(imps) for f, imps in all_features.items()}
                summary['common_important_features'] = sorted(
                    avg_importance.items(), key=lambda x: x[1], reverse=True
                )[:10]
            
            # ç­–ç•¥æ´å¯Ÿ
            if 'decision_tree' in self.extracted_rules:
                dt_rules = self.extracted_rules['decision_tree'].get('readable_rules', [])
                high_confidence_rules = [r for r in dt_rules if r.get('confidence', 0) > 0.8]
                summary['strategy_insights'].append(f"å‘ç°{len(high_confidence_rules)}æ¡é«˜ç½®ä¿¡åº¦è§„åˆ™")
            
            if self.training_data:
                action_dist = np.bincount(self.training_data['actions'])
                dominant_action = np.argmax(action_dist)
                dominant_ratio = action_dist[dominant_action] / len(self.training_data['actions'])
                summary['strategy_insights'].append(f"ç­–ç•¥å€¾å‘äºAction_{dominant_action} (å æ¯”{dominant_ratio:.1%})")
            
            return summary
            
        except Exception as e:
            self.logger.error(f"è·å–ç­–ç•¥æ‘˜è¦å¤±è´¥: {e}")
            return {"error": str(e)}

def main():
    """æµ‹è¯•è§„åˆ™æå–å™¨åŠŸèƒ½"""
    print("ğŸ“ æµ‹è¯•äº¤æ˜“è§„åˆ™æå–å™¨")
    
    # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®
    np.random.seed(42)
    n_samples = 1000
    n_features = 20
    
    # æ¨¡æ‹ŸçŠ¶æ€ç‰¹å¾
    states = np.random.randn(n_samples, n_features)
    
    # æ¨¡æ‹Ÿç­–ç•¥å†³ç­–ï¼ˆç®€å•è§„åˆ™ï¼‰
    actions = []
    for state in states:
        if state[0] > 0.5 and state[1] < -0.3:  # ä¹°å…¥æ¡ä»¶
            action = 1
        elif state[0] < -0.5 and state[1] > 0.3:  # å–å‡ºæ¡ä»¶
            action = 2
        elif abs(state[0]) < 0.2:  # å¹³ä»“æ¡ä»¶
            action = 3
        else:  # æŒæœ‰
            action = 0
        actions.append(action)
    
    actions = np.array(actions)
    
    # ç‰¹å¾åç§°
    feature_names = [f'feature_{i}' for i in range(n_features)]
    
    # åˆ›å»ºæå–å™¨
    extractor = TradingRuleExtractor(feature_names=feature_names)
    
    # æå–è§„åˆ™
    print("ğŸŒ² æå–å†³ç­–æ ‘è§„åˆ™...")
    dt_result = extractor.extract_decision_tree_rules(states, actions, max_depth=5)
    print(f"å†³ç­–æ ‘å‡†ç¡®ç‡: {dt_result.get('accuracy', 0):.3f}")
    
    print("ğŸŒ³ æå–éšæœºæ£®æ—è§„åˆ™...")
    rf_result = extractor.extract_random_forest_rules(states, actions, n_trees=20)
    print(f"éšæœºæ£®æ—å‡†ç¡®ç‡: {rf_result.get('accuracy', 0):.3f}")
    
    print("ğŸ“ˆ æå–é€»è¾‘å›å½’è§„åˆ™...")
    lr_result = extractor.extract_logistic_regression_rules(states, actions)
    print(f"é€»è¾‘å›å½’å‡†ç¡®ç‡: {lr_result.get('accuracy', 0):.3f}")
    
    # ç”ŸæˆæŠ¥å‘Š
    print("ğŸ“‹ ç”Ÿæˆè§„åˆ™æ‘˜è¦æŠ¥å‘Š...")
    report_path = extractor.create_rule_summary_report()
    if report_path:
        print(f"æŠ¥å‘Šå·²ä¿å­˜: {report_path}")
    
    # è·å–ç­–ç•¥æ‘˜è¦
    summary = extractor.get_trading_strategy_summary()
    print("ğŸ“Š ç­–ç•¥æ‘˜è¦:")
    for key, value in summary.items():
        if key != 'details':
            print(f"  {key}: {value}")
    
    print("âœ… è§„åˆ™æå–å™¨æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    main() 