#!/usr/bin/env python3
"""
SOL/USDTé‡åŒ–äº¤æ˜“ç³»ç»Ÿ - ä¸»ç¨‹åº
é›†æˆå¼ºåŒ–å­¦ä¹ ã€SMCåˆ†æå’Œå¢å¼ºé£æ§çš„å®Œæ•´äº¤æ˜“è§£å†³æ–¹æ¡ˆ
"""
import os
import sys
import argparse
from pathlib import Path
from datetime import datetime
import warnings
import time
import hashlib
import pandas as pd
import numpy as np
import pickle

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(str(Path(__file__).parent))

from data.data_collector import DataCollector
from data.technical_indicators import TechnicalIndicators
from data.smc_signals import SMCSignals
from environment.trading_env import SolUsdtTradingEnv, make_env
from analysis.trading_visualizer import TradingVisualizer
from utils.config import get_config
from utils.logger import get_logger
from data.data_splitter import TimeSeriesDataSplitter
from training.enhanced_trainer import EnhancedTrainer

# å¼ºåŒ–å­¦ä¹ ç›¸å…³å¯¼å…¥
try:
    from stable_baselines3 import PPO
    from stable_baselines3.common.vec_env import DummyVecEnv, VecNormalize
    from stable_baselines3.common.callbacks import (
        EvalCallback, CheckpointCallback, BaseCallback
    )
    import tensorboard
    
    # âœ… æ–°å¢ï¼šå¯¼å…¥sb3_contribç”¨äºRecurrentPPO
    try:
        from sb3_contrib import RecurrentPPO
        RECURRENT_PPO_AVAILABLE = True
        print("âœ… sb3_contribå¯ç”¨ï¼Œæ”¯æŒRecurrentPPO")
    except ImportError:
        RECURRENT_PPO_AVAILABLE = False
        print("âš ï¸ sb3_contribä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨æ ‡å‡†PPOä»£æ›¿")
    
    REINFORCEMENT_LEARNING_AVAILABLE = True
    print("âœ… å¼ºåŒ–å­¦ä¹ åº“åŠ è½½æˆåŠŸ")
    
except ImportError as e:
    print(f"âš ï¸ å¼ºåŒ–å­¦ä¹ åº“ä¸å¯ç”¨: {e}")
    print("ğŸ’¡ è¯·å®‰è£…: pip install stable-baselines3[extra] sb3_contrib")
    REINFORCEMENT_LEARNING_AVAILABLE = False
    RECURRENT_PPO_AVAILABLE = False

config = get_config()
logger = get_logger('MainSystem', 'main.log')

warnings.filterwarnings('ignore')

class DataCache:
    """âœ… æ•°æ®ç¼“å­˜ç®¡ç†å™¨ - é¿å…é‡å¤è®¡ç®—"""
    
    def __init__(self, cache_dir: str = "cache"):
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(exist_ok=True)
        
    def _get_data_hash(self, df) -> str:
        """è®¡ç®—æ•°æ®hashå€¼"""
        return hashlib.md5(str(df.shape).encode() + str(df.index[0]).encode() + str(df.index[-1]).encode()).hexdigest()
    
    def get_processed_data(self, df, force_refresh: bool = False):
        """è·å–å¤„ç†åçš„æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        data_hash = self._get_data_hash(df)
        cache_file = self.cache_dir / f"processed_data_{data_hash}.pkl"
        
        # æ£€æŸ¥ç¼“å­˜
        if not force_refresh and cache_file.exists():
            try:
                with open(cache_file, 'rb') as f:
                    cached_data = pickle.load(f)
                    print(f"âœ… ä»ç¼“å­˜åŠ è½½å¤„ç†åçš„æ•°æ®: {cache_file}")
                    return cached_data
            except Exception as e:
                print(f"âš ï¸ ç¼“å­˜åŠ è½½å¤±è´¥: {e}")
        
        # è®¡ç®—æŠ€æœ¯æŒ‡æ ‡å’ŒSMCä¿¡å·
        print("ğŸ”„ è®¡ç®—æŠ€æœ¯æŒ‡æ ‡...")
        indicator_calculator = TechnicalIndicators()
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰æŒ‡æ ‡
        if 'rsi' not in df.columns:
            df = indicator_calculator.calculate_all_indicators(df)
        else:
            print("âœ… æŠ€æœ¯æŒ‡æ ‡å·²å­˜åœ¨ï¼Œè·³è¿‡è®¡ç®—")
        
        print("ğŸ¯ è®¡ç®—SMCä¿¡å·...")
        smc_calculator = SMCSignals()
        
        # æ£€æŸ¥æ˜¯å¦å·²æœ‰SMCä¿¡å·
        if 'smc_signal' not in df.columns:
            df = smc_calculator.calculate_all_smc_signals(df)
        else:
            print("âœ… SMCä¿¡å·å·²å­˜åœ¨ï¼Œè·³è¿‡è®¡ç®—")
        
        # ä¿å­˜åˆ°ç¼“å­˜
        try:
            with open(cache_file, 'wb') as f:
                pickle.dump(df, f)
                print(f"ğŸ’¾ æ•°æ®å·²ç¼“å­˜è‡³: {cache_file}")
        except Exception as e:
            print(f"âš ï¸ ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
        
        return df

def setup_directories():
    """è®¾ç½®å¿…è¦çš„ç›®å½•ç»“æ„ - å¢å¼ºç‰ˆ"""
    config = get_config()
    directories = [
        config.get('DATA_DIR'),
        config.get('MODEL_DIR'),
        config.get('LOG_DIR'),
        config.get('RESULTS_DIR'),
        'cache',  # æ–°å¢ç¼“å­˜ç›®å½•
        'logs/tensorboard',  # TensorBoardæ—¥å¿—ç›®å½•
        'logs/eval',  # è¯„ä¼°æ—¥å¿—ç›®å½•
        'models/best',  # æœ€ä½³æ¨¡å‹ç›®å½•
        'models/checkpoints'  # æ£€æŸ¥ç‚¹ç›®å½•
    ]
    
    for directory in directories:
        try:
            os.makedirs(directory, exist_ok=True)
            print(f"ğŸ“ ç›®å½•å·²åˆ›å»º/ç¡®è®¤: {directory}")
        except Exception as e:
            print(f"âš ï¸ åˆ›å»ºç›®å½•å¤±è´¥ {directory}: {e}")
    
    # æ¸…ç†å¯èƒ½å­˜åœ¨çš„TensorBoardæ—¥å¿—å†²çª
    tensorboard_dir = "logs/tensorboard"
    if os.path.exists(tensorboard_dir):
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶å†²çª
        for item in os.listdir(tensorboard_dir):
            item_path = os.path.join(tensorboard_dir, item)
            if os.path.isfile(item_path) and item.startswith("PPO"):
                # åˆ é™¤å¯èƒ½çš„å†²çªæ–‡ä»¶
                try:
                    os.remove(item_path)
                    print(f"ğŸ—‘ï¸ æ¸…ç†TensorBoardå†²çªæ–‡ä»¶: {item}")
                except Exception as e:
                    print(f"âš ï¸ æ¸…ç†æ–‡ä»¶å¤±è´¥ {item}: {e}")
    
    print("âœ… ç›®å½•ç»“æ„è®¾ç½®å®Œæˆ")

def collect_data():
    """æ•°æ®æ”¶é›†æ¨¡å¼"""
    print("ğŸ”„ å¼€å§‹æ•°æ®æ”¶é›†...")
    
    collector = DataCollector()
    
    # è·å–å†å²æ•°æ®
    df = collector.get_historical_data()
    
    if not df.empty:
        # ä¿å­˜åŸå§‹æ•°æ®
        filepath = collector.save_data(df)
        
        # ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨å¤„ç†æ•°æ®
        cache_manager = DataCache()
        df_processed = cache_manager.get_processed_data(df)
        
        # ä¿å­˜å®Œæ•´æ•°æ®
        complete_filepath = filepath.replace('.csv', '_complete.csv')
        df_processed.to_csv(complete_filepath)
        
        print(f"âœ… æ•°æ®æ”¶é›†å®Œæˆ!")
        print(f"ğŸ“ˆ åŸå§‹æ•°æ®: {len(df)} æ¡è®°å½•")
        print(f"ğŸ”¢ æŠ€æœ¯æŒ‡æ ‡æ•°é‡: {len([col for col in df_processed.columns if col not in df.columns])}")
        print(f"ğŸ’¾ å®Œæ•´æ•°æ®ä¿å­˜è‡³: {complete_filepath}")
        
        # æ˜¾ç¤ºæ•°æ®æ‘˜è¦
        print(f"\nğŸ“Š æ•°æ®æ‘˜è¦:")
        print(f"æ—¶é—´èŒƒå›´: {df.index.min()} åˆ° {df.index.max()}")
        print(f"ä»·æ ¼èŒƒå›´: ${df['close'].min():.2f} - ${df['close'].max():.2f}")
        print(f"å¹³å‡æˆäº¤é‡: {df['volume'].mean():.0f}")
        
        return df_processed
    else:
        print("âŒ æ•°æ®æ”¶é›†å¤±è´¥")
        return None

def train_model(df=None):
    """
    âœ… ä¼˜åŒ–ç‰ˆè®­ç»ƒå‡½æ•° - æ”¯æŒå¤šç§æ¨¡å‹è®­ç»ƒ
    """
    print("ğŸš€ å¼€å§‹æ™ºèƒ½è®­ç»ƒæµç¨‹...")
    start_time = time.time()
    
    try:
        # æ•°æ®å‡†å¤‡
        if df is None:
            cache = DataCache()
            df = cache.get_processed_data(None, force_refresh=False)
            if df is None or df.empty:
                print("âŒ æ— æ³•è·å–è®­ç»ƒæ•°æ®")
                return None
        
        print(f"ğŸ“Š æ•°æ®æ¦‚è§ˆ: {len(df)} æ¡è®°å½•, æ—¶é—´è·¨åº¦: {df.index[0]} åˆ° {df.index[-1]}")
        
        # âœ… ä¿®æ”¹ï¼šä½¿ç”¨è¾ƒå°‘çš„è®­ç»ƒæ­¥æ•°ä»¥ä¾¿å¿«é€Ÿæµ‹è¯•
        training_config = {
            'total_timesteps': 50000,  # å‡å°‘åˆ°5ä¸‡æ­¥ï¼Œçº¦10-15åˆ†é’Ÿè®­ç»ƒ
            'eval_freq': 5000,        # æ¯5åƒæ­¥è¯„ä¼°ä¸€æ¬¡
            'n_eval_episodes': 3,     # å‡å°‘è¯„ä¼°å›åˆæ•°
            'save_freq': 10000,       # æ¯1ä¸‡æ­¥ä¿å­˜ä¸€æ¬¡
            'log_interval': 1000      # æ¯1åƒæ­¥è®°å½•ä¸€æ¬¡
        }
        
        print(f"âš¡ å¿«é€Ÿæµ‹è¯•æ¨¡å¼: {training_config['total_timesteps']} æ­¥è®­ç»ƒ")
        
        trainer = EnhancedTrainer()
        
        # æ•°æ®åˆ†å‰²ï¼ˆä½¿ç”¨æ›´å°çš„éªŒè¯é›†ï¼‰
        train_df, val_df, test_df = trainer.prepare_data(df)
        print(f"ğŸ“Š æ•°æ®åˆ†å‰²: è®­ç»ƒ {len(train_df)}, éªŒè¯ {len(val_df)}, æµ‹è¯• {len(test_df)}")
        
        # åˆ›å»ºç¯å¢ƒ
        train_env, eval_env = trainer.create_environments(train_df, val_df)
        print(f"ğŸ¢ ç¯å¢ƒåˆ›å»ºå®Œæˆ: è§‚æµ‹ç©ºé—´ {train_env.observation_space}, åŠ¨ä½œç©ºé—´ {train_env.action_space}")
        
        # âœ… ä½¿ç”¨å•ä¸€æ¨¡å‹è¿›è¡Œå¿«é€Ÿæµ‹è¯•
        model_type = 'PPO_STANDARD'  # ä½¿ç”¨æœ€ç¨³å®šçš„PPO
        print(f"ğŸ¯ å¼€å§‹è®­ç»ƒ {model_type} æ¨¡å‹ï¼ˆå¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼‰")
        
        # è®­ç»ƒæ¨¡å‹
        if model_type == 'PPO_STANDARD':
            model_path = trainer.train_ppo_standard(train_env, eval_env, training_config['total_timesteps'])
        else:
            print(f"âŒ æš‚ä¸æ”¯æŒ {model_type} æ¨¡å‹")
            return None
        
        if model_path:
            print(f"âœ… æ¨¡å‹è®­ç»ƒæˆåŠŸ: {model_path}")
            
            # å¿«é€ŸéªŒè¯æµ‹è¯•
            print("ğŸ§ª å¼€å§‹å¿«é€ŸéªŒè¯æµ‹è¯•...")
            test_results = trainer._quick_model_test(model_path, test_df)
            
            if test_results:
                print(f"ğŸ“Š æµ‹è¯•ç»“æœ: æ”¶ç›Šç‡ {test_results.get('total_return', 0):.2%}, "
                      f"å¤æ™®æ¯”ç‡ {test_results.get('sharpe_ratio', 0):.3f}")
            
            training_time = time.time() - start_time
            print(f"â±ï¸ è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.1f}ç§’")
            
            return model_path
        else:
            print("âŒ æ¨¡å‹è®­ç»ƒå¤±è´¥")
            return None
            
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        return None

def train_model_legacy(df=None):
    """
    âœ… ä¼ ç»Ÿè®­ç»ƒæ¨¡å¼ - ä½œä¸ºåå¤‡é€‰é¡¹
    """
    if df is None:
        collector = DataCollector()
        df = collector.load_data()
        
        if df.empty:
            print("âŒ æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®ï¼Œå¼€å§‹è·å–å†å²æ•°æ®...")
            df = collector.get_historical_data()
            if not df.empty:
                collector.save_data(df)
            else:
                print("âŒ æ•°æ®è·å–å¤±è´¥")
                return None

    print(f"ğŸ“ˆ ä½¿ç”¨æ•°æ®: {len(df)} æ¡è®°å½• (æ—¶é—´èŒƒå›´: {df.index.min()} åˆ° {df.index.max()})")
    
    # âœ… æ–°å¢ï¼šä½¿ç”¨æ•°æ®åˆ’åˆ†å™¨è¿›è¡Œè®­ç»ƒæµ‹è¯•åˆ†ç¦»
    splitter = TimeSeriesDataSplitter()
    train_df, val_df, test_df = splitter.split_data(df)
    
    print("ğŸ”„ æ•°æ®åˆ’åˆ†å®Œæˆ:")
    print(f"  ğŸ“š è®­ç»ƒé›†: {len(train_df):,} æ¡è®°å½• ({train_df.index.min()} åˆ° {train_df.index.max()})")
    print(f"  ğŸ“‹ éªŒè¯é›†: {len(val_df):,} æ¡è®°å½• ({val_df.index.min()} åˆ° {val_df.index.max()})")
    print(f"  ğŸ§ª æµ‹è¯•é›†: {len(test_df):,} æ¡è®°å½• ({test_df.index.min()} åˆ° {test_df.index.max()})")
    
    # ç§»é™¤æ•°æ®é›†æ ‡è¯†åˆ—ï¼ˆé¿å…æ¨¡å‹å­¦ä¹ åˆ°è¿™ä¸ªä¿¡æ¯ï¼‰
    for dataset in [train_df, val_df, test_df]:
        if 'dataset_type' in dataset.columns:
            dataset.drop('dataset_type', axis=1, inplace=True)
    
    # ä½¿ç”¨ç¼“å­˜ç®¡ç†å™¨å¤„ç†è®­ç»ƒæ•°æ®
    cache_manager = DataCache()
    train_df_processed = cache_manager.get_processed_data(train_df, force_refresh=True)
    
    # åˆ›å»ºè®­ç»ƒç¯å¢ƒ - åªä½¿ç”¨è®­ç»ƒæ•°æ®
    print("ğŸ—ï¸ åˆ›å»ºè®­ç»ƒç¯å¢ƒï¼ˆä»…ä½¿ç”¨è®­ç»ƒæ•°æ®ï¼‰...")
    def make_env_func(data, mode='train'):
        def _init():
            return SolUsdtTradingEnv(data, mode=mode)
        return _init
    
    # åˆ›å»ºå‘é‡åŒ–ç¯å¢ƒ
    n_envs = config.get('N_ENVS', 4)
    train_env = DummyVecEnv([make_env_func(train_df_processed, 'train') for _ in range(n_envs)])
    train_env = VecNormalize(train_env, norm_obs=True, norm_reward=True)
    
    # éªŒè¯ç¯å¢ƒ - ä½¿ç”¨éªŒè¯æ•°æ®
    val_df_processed = cache_manager.get_processed_data(val_df, force_refresh=False)
    eval_env = DummyVecEnv([make_env_func(val_df_processed, 'eval')])
    eval_env = VecNormalize(eval_env, norm_obs=True, norm_reward=True, training=False)
    
    # âœ… ä¿å­˜æµ‹è¯•æ•°æ®ä¾›åç»­å›æµ‹ä½¿ç”¨
    test_data_path = "data/test_data.pkl"
    test_df.to_pickle(test_data_path)
    print(f"ğŸ’¾ æµ‹è¯•æ•°æ®å·²ä¿å­˜è‡³: {test_data_path}")
    
    # âœ… ä½¿ç”¨ä¼˜åŒ–çš„æ¨¡å‹é…ç½®
    active_model = config.get('ACTIVE_MODEL', 'PPO_LSTM')
    model_configs = config.get('MODEL_CONFIGS', {})
    
    if active_model in model_configs:
        model_config = model_configs[active_model]
        print(f"ğŸ¯ ä½¿ç”¨æ¨¡å‹é…ç½®: {active_model}")
    else:
        # ä½¿ç”¨é»˜è®¤é…ç½®
        model_config = {
            'policy': 'MlpPolicy',
            'learning_rate': 2.5e-4,
            'gamma': 0.99,
            'clip_range': 0.2,
            'n_steps': 2048,
            'batch_size': 512,
            'n_epochs': 10,
            'ent_coef': 0.01,
            'vf_coef': 0.5,
            'max_grad_norm': 0.5,
            'gae_lambda': 0.95,
            'verbose': 1
        }
        print("ğŸ¯ ä½¿ç”¨é»˜è®¤PPOé…ç½®")
    
    print("ğŸ§  åˆå§‹åŒ–PPOæ¨¡å‹...")
    
    try:
        # âœ… æ ¹æ®é…ç½®é€‰æ‹©ç®—æ³•
        algorithm_type = model_config.get('algorithm', 'PPO')
        
        # ä»é…ç½®ä¸­ç§»é™¤algorithmå­—æ®µï¼Œé¿å…ä¼ é€’ç»™æ¨¡å‹æ„é€ å‡½æ•°
        model_params = {k: v for k, v in model_config.items() if k != 'algorithm'}
        
        if algorithm_type == 'RecurrentPPO' and RECURRENT_PPO_AVAILABLE:
            # ä½¿ç”¨RecurrentPPO for LSTM
            print("ğŸ§  åˆå§‹åŒ–RecurrentPPOæ¨¡å‹...")
            
            # âœ… ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„ç­–ç•¥ç±»å‹
            if model_params.get('policy') == 'MlpPolicy':
                model_params['policy'] = 'MlpLstmPolicy'
                print("ğŸ“ ç­–ç•¥ç±»å‹å·²è°ƒæ•´ä¸ºMlpLstmPolicyï¼ˆRecurrentPPOä¸“ç”¨ï¼‰")
            
            # âœ… å¤„ç†policy_kwargsä¸­çš„RecurrentPPOç‰¹æœ‰å‚æ•°
            policy_kwargs = model_params.get('policy_kwargs', {})
            # ç§»é™¤å¯èƒ½å†²çªçš„å‚æ•°ï¼ŒRecurrentPPOä¼šè‡ªåŠ¨å¤„ç†è¿™äº›
            cleaned_policy_kwargs = {k: v for k, v in policy_kwargs.items() 
                                   if k not in ['enable_critic_lstm', 'lstm_hidden_size']}
            model_params['policy_kwargs'] = cleaned_policy_kwargs
            
            # âœ… æ·»åŠ è¯Šæ–­ä¿¡æ¯
            print(f"ğŸ” RecurrentPPO é…ç½®è¯Šæ–­:")
            print(f"   ç­–ç•¥ç±»å‹: {model_params.get('policy')}")
            print(f"   å­¦ä¹ ç‡: {model_params.get('learning_rate')}")
            print(f"   ç½‘ç»œæ¶æ„: {model_params.get('policy_kwargs', {})}")
            print(f"   ç¯å¢ƒç±»å‹: {type(train_env)}")
            print(f"   è§‚æµ‹ç©ºé—´: {train_env.observation_space}")
            print(f"   åŠ¨ä½œç©ºé—´: {train_env.action_space}")
            
            model = RecurrentPPO(
                env=train_env,
                **model_params
            )
            print("âœ… RecurrentPPOæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ (æ”¯æŒLSTM)")
        else:
            # ä½¿ç”¨æ ‡å‡†PPOï¼ˆå…¼å®¹æ€§å›é€€ï¼‰
            if algorithm_type == 'RecurrentPPO':
                print("âš ï¸ RecurrentPPOä¸å¯ç”¨ï¼Œå›é€€åˆ°æ ‡å‡†PPO")
                # å¦‚æœæ˜¯RecurrentPPOé…ç½®ï¼Œéœ€è¦è°ƒæ•´policyå‚æ•°
                if model_params.get('policy') == 'MlpLstmPolicy':
                    model_params['policy'] = 'MlpPolicy'
                    print("ğŸ“ ç­–ç•¥ç±»å‹å·²è°ƒæ•´ä¸ºMlpPolicy")
            
            print("ğŸ§  åˆå§‹åŒ–æ ‡å‡†PPOæ¨¡å‹...")
            # ç§»é™¤RecurrentPPOç‰¹æœ‰çš„å‚æ•°
            ppo_params = {k: v for k, v in model_params.items() 
                         if k not in ['enable_critic_lstm', 'lstm_hidden_size', 'target_kl']}
            
            model = PPO(
                env=train_env,
                **ppo_params
            )
            print("âœ… æ ‡å‡†PPOæ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
            
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        print("ğŸ” è¯Šæ–­ä¿¡æ¯:")
        print(f"   è®­ç»ƒç¯å¢ƒç±»å‹: {type(train_env)}")
        print(f"   è§‚æµ‹ç©ºé—´: {train_env.observation_space}")
        print(f"   åŠ¨ä½œç©ºé—´: {train_env.action_space}")
        print(f"   é…ç½®çš„ç®—æ³•ç±»å‹: {model_config.get('algorithm', 'PPO')}")
        print(f"   RecurrentPPOå¯ç”¨æ€§: {RECURRENT_PPO_AVAILABLE}")
        return None
    
    # âœ… ä¿ç•™æœ‰ç”¨çš„å›è°ƒå‡½æ•°
    # è¯„ä¼°å›è°ƒ
    eval_callback = EvalCallback(
        eval_env,
        best_model_save_path='./models/best/',
        log_path='./logs/eval/',
        eval_freq=10000,
        deterministic=True,
        render=False,
        verbose=1
    )
    
    # æ£€æŸ¥ç‚¹å›è°ƒ
    checkpoint_callback = CheckpointCallback(
        save_freq=100000,
        save_path='./models/checkpoints/',
        name_prefix='ppo_sol_trading'
    )
    
    # âœ… è®­ç»ƒè¿›åº¦ç›‘æ§å›è°ƒ
    class TrainingProgressCallback(BaseCallback):
        def __init__(self, verbose=0):
            super(TrainingProgressCallback, self).__init__(verbose)
            self.start_time = time.time()
            self.last_checkpoint = 0
            
        def _on_step(self) -> bool:
            # æ¯10ä¸‡æ­¥æ˜¾ç¤ºè¯¦ç»†è¿›åº¦
            if self.num_timesteps - self.last_checkpoint >= 100000:
                elapsed_time = time.time() - self.start_time
                progress = self.num_timesteps / self.model.num_timesteps
                estimated_total_time = elapsed_time / progress
                remaining_time = estimated_total_time - elapsed_time
                
                print(f"\n" + "="*60)
                print(f"ğŸ“Š è®­ç»ƒè¿›åº¦æ£€æŸ¥ç‚¹ - æ­¥æ•°: {self.num_timesteps:,}")
                print(f"ğŸ“ˆ å®Œæˆè¿›åº¦: {progress*100:.2f}%")
                print(f"â±ï¸  å·²ç”¨æ—¶é—´: {elapsed_time/3600:.2f}å°æ—¶")
                print(f"â³ å‰©ä½™æ—¶é—´: {remaining_time/3600:.2f}å°æ—¶")
                print(f"ğŸš€ å¹³å‡é€Ÿåº¦: {self.num_timesteps/elapsed_time:.1f} æ­¥/ç§’")
                print("="*60)
                
                self.last_checkpoint = self.num_timesteps
            
            return True
    
    progress_callback = TrainingProgressCallback()
    
    # ç»„åˆæ‰€æœ‰å›è°ƒ
    callbacks = [eval_callback, checkpoint_callback, progress_callback]
    
    # å¼€å§‹è®­ç»ƒ
    total_timesteps = config.get('TOTAL_TIMESTEPS', 2000000)
    print(f"\nğŸš€ å¼€å§‹è®­ç»ƒ - æ€»æ­¥æ•°: {total_timesteps:,}")
    print(f"ğŸ’¾ æ¨¡å‹ä¿å­˜è·¯å¾„: ./models/")
    print(f"ğŸ”§ ç¯å¢ƒæ•°é‡: {n_envs}")
    print(f"âš™ï¸  è®­ç»ƒå‚æ•°: å­¦ä¹ ç‡={model_config.get('learning_rate')}, æ‰¹æ¬¡={model_config.get('batch_size')}")
    
    # æ·»åŠ ç¯å¢ƒè¯Šæ–­ä¿¡æ¯
    print(f"\nğŸ” ç¯å¢ƒè¯Šæ–­ä¿¡æ¯:")
    print(f"   æ•°æ®é›†å¤§å°: {len(df)} è¡Œ")
    print(f"   ç‰¹å¾ç»´åº¦: {len(df.columns)} åˆ—")
    print(f"   è§‚æµ‹ç©ºé—´ç»´åº¦: {train_env.observation_space.shape}")
    print(f"   åŠ¨ä½œç©ºé—´: {train_env.action_space}")
    
    # æµ‹è¯•ç¯å¢ƒé‡ç½®
    try:
        reset_result = train_env.reset()
        
        # âœ… å…¼å®¹ä¸åŒç‰ˆæœ¬çš„gym/gymnasiumå’Œå‘é‡åŒ–ç¯å¢ƒ
        if isinstance(reset_result, tuple) and len(reset_result) == 2:
            # æ–°ç‰ˆæœ¬æ ¼å¼: (observation, info)
            test_obs, test_info = reset_result
        elif isinstance(reset_result, np.ndarray):
            # æ—§ç‰ˆæœ¬æ ¼å¼æˆ–å‘é‡åŒ–ç¯å¢ƒ: åªè¿”å›observation
            test_obs = reset_result
            test_info = {}
        else:
            # å…¶ä»–æƒ…å†µï¼Œå°è¯•è·å–è§‚æµ‹
            test_obs = reset_result
            test_info = {}
            
        print(f"   æµ‹è¯•è§‚æµ‹å‘é‡å½¢çŠ¶: {test_obs.shape}")
        print(f"   è§‚æµ‹å‘é‡æ ·æœ¬: {test_obs[0][:5]}...")  # æ˜¾ç¤ºå‰5ä¸ªå€¼
        print("âœ… ç¯å¢ƒæµ‹è¯•é€šè¿‡")
    except Exception as e:
        print(f"âŒ ç¯å¢ƒæµ‹è¯•å¤±è´¥: {e}")
        return None
    
    try:
        training_start_time = time.time()
        
        model.learn(
            total_timesteps=total_timesteps,
            callback=callbacks,
            progress_bar=True
        )
        
        training_end_time = time.time()
        training_duration = training_end_time - training_start_time
        
        # ä¿å­˜æœ€ç»ˆæ¨¡å‹
        model_save_path = f"models/ppo_sol_trading_final_{total_timesteps}.zip"
        model.save(model_save_path)
        
        # ä¿å­˜ç¯å¢ƒå½’ä¸€åŒ–å‚æ•°
        train_env.save("models/vec_normalize.pkl")
        
        print(f"\nâœ… è®­ç»ƒå®Œæˆï¼")
        print(f"â±ï¸  è®­ç»ƒè€—æ—¶: {training_duration/3600:.2f}å°æ—¶")
        print(f"ğŸš€ å¹³å‡è®­ç»ƒé€Ÿåº¦: {total_timesteps/training_duration:.1f} æ­¥/ç§’")
        print(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜è‡³: {model_save_path}")
        print(f"ğŸ“Š å¯åŠ¨TensorBoard: tensorboard --logdir=logs/tensorboard/")
        
        return model_save_path
        
    except Exception as e:
        print(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        return None

def backtest_model(df=None, model_path=None):
    """
    âœ… ä¼˜åŒ–çš„å›æµ‹æ¨¡å¼ - ä½¿ç”¨ç‹¬ç«‹æµ‹è¯•æ•°æ®é˜²æ­¢æ³„éœ²
    """
    if model_path is None:
        model_path = "models/ppo_sol_trading_final.zip"
    
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–æ£€æŸ¥æ¨¡å‹è·¯å¾„")
        return None
    
    print(f"ğŸ“Š å¼€å§‹æ¨¡å‹å›æµ‹ï¼Œæ¨¡å‹è·¯å¾„: {model_path}")
    
    # âœ… ä¼˜å…ˆä½¿ç”¨ç‹¬ç«‹çš„æµ‹è¯•æ•°æ®
    test_data_path = "data/test_data.pkl"
    
    if os.path.exists(test_data_path) and df is None:
        print("ğŸ“‹ ä½¿ç”¨ç‹¬ç«‹æµ‹è¯•æ•°æ®è¿›è¡Œå›æµ‹...")
        try:
            df = pd.read_pickle(test_data_path)
            print(f"âœ… æµ‹è¯•æ•°æ®åŠ è½½æˆåŠŸ: {len(df)} æ¡è®°å½•")
            print(f"ğŸ“… æµ‹è¯•æ•°æ®æ—¶é—´èŒƒå›´: {df.index.min()} åˆ° {df.index.max()}")
            print("ğŸ”’ è¿™äº›æ•°æ®åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­æœªè¢«ä½¿ç”¨ï¼Œç¡®ä¿å›æµ‹ç»“æœçš„çœŸå®æ€§")
        except Exception as e:
            print(f"âŒ æµ‹è¯•æ•°æ®åŠ è½½å¤±è´¥: {e}")
            df = None
    
    # å¦‚æœæ²¡æœ‰æµ‹è¯•æ•°æ®ï¼Œå›é€€åˆ°å¸¸è§„æ•°æ®åŠ è½½
    if df is None:
        print("âš ï¸  æœªæ‰¾åˆ°ç‹¬ç«‹æµ‹è¯•æ•°æ®ï¼Œä½¿ç”¨å®Œæ•´æ•°æ®é›†è¿›è¡Œå›æµ‹")
        print("âš ï¸  æ³¨æ„ï¼šè¿™å¯èƒ½åŒ…å«è®­ç»ƒæœŸé—´ä½¿ç”¨çš„æ•°æ®")
        
        collector = DataCollector()
        df = collector.load_data()
        
        if df.empty:
            print("âŒ æœªæ‰¾åˆ°å›æµ‹æ•°æ®ï¼Œè¯·å…ˆè¿è¡Œæ•°æ®æ”¶é›†")
            return None
    
    print(f"ğŸ“ˆ å›æµ‹æ•°æ®: {len(df)} æ¡è®°å½•")
    
    # ç¡®ä¿æ•°æ®å·²å¤„ç†
    try:
        # æ£€æŸ¥æ˜¯å¦æœ‰å¿…è¦çš„ç‰¹å¾åˆ—
        required_features = ['rsi', 'bb_position', 'ema_fast', 'smc_signal']
        missing_features = [f for f in required_features if f not in df.columns]
        
        if missing_features:
            print(f"ğŸ”§ æ£€æµ‹åˆ°ç¼ºå¤±ç‰¹å¾: {missing_features}")
            print("ğŸ”„ é‡æ–°å¤„ç†å›æµ‹æ•°æ®...")
            
            # é‡æ–°è®¡ç®—æŒ‡æ ‡
            from data.technical_indicators import TechnicalIndicators
            from data.smc_signals import SMCSignals
            
            indicator_calculator = TechnicalIndicators()
            df = indicator_calculator.calculate_all_indicators(df)
            
            smc_calculator = SMCSignals()
            df = smc_calculator.calculate_all_smc_signals(df)
            
            # å¡«å……ç¼ºå¤±å€¼
            df = df.fillna(method='ffill').fillna(0)
            print("âœ… å›æµ‹æ•°æ®å¤„ç†å®Œæˆ")
        
    except Exception as e:
        print(f"âŒ å›æµ‹æ•°æ®å¤„ç†å¤±è´¥: {e}")
        return None
    
    try:
        # åŠ è½½æ¨¡å‹
        print("ğŸ§  åŠ è½½PPOæ¨¡å‹...")
        model = PPO.load(model_path)
        
        # åŠ è½½ç¯å¢ƒå½’ä¸€åŒ–å‚æ•°
        vec_normalize_path = "models/vec_normalize.pkl"
        if os.path.exists(vec_normalize_path):
            print("ğŸ“ åŠ è½½ç¯å¢ƒå½’ä¸€åŒ–å‚æ•°...")
        
        # åˆ›å»ºå›æµ‹ç¯å¢ƒ
        print("ğŸ—ï¸ åˆ›å»ºå›æµ‹ç¯å¢ƒ...")
        env = SolUsdtTradingEnv(df, mode='test')
        
        # ç¡®ä¿ä½¿ç”¨ä¸è®­ç»ƒæ—¶ç›¸åŒçš„å½’ä¸€åŒ–
        if os.path.exists(vec_normalize_path):
            try:
                # ç”±äºVecNormalizeéœ€è¦å‘é‡åŒ–ç¯å¢ƒï¼Œæˆ‘ä»¬æ‰‹åŠ¨å¤„ç†å½’ä¸€åŒ–
                print("â„¹ï¸  æ³¨æ„ï¼šå›æµ‹ç¯å¢ƒå°†ä½¿ç”¨åŸå§‹æ•°æ®ï¼Œæœªåº”ç”¨è®­ç»ƒæ—¶çš„å½’ä¸€åŒ–")
            except Exception as e:
                print(f"âš ï¸  å½’ä¸€åŒ–å‚æ•°åŠ è½½å¤±è´¥: {e}")
        
        # è¿è¡Œå›æµ‹
        print("ğŸš€ å¼€å§‹å›æµ‹...")
        reset_result = env.reset()
        
        # âœ… å…¼å®¹ä¸åŒç‰ˆæœ¬çš„gym/gymnasium
        if isinstance(reset_result, tuple) and len(reset_result) == 2:
            # æ–°ç‰ˆæœ¬æ ¼å¼: (observation, info)
            obs, info = reset_result
        elif isinstance(reset_result, np.ndarray):
            # æ—§ç‰ˆæœ¬æ ¼å¼: åªè¿”å›observation
            obs = reset_result
            info = {}
        else:
            # å…¶ä»–æƒ…å†µï¼Œå°è¯•è·å–è§‚æµ‹
            obs = reset_result
            info = {}
            
        done = False
        step_count = 0
        
        while not done:
            action, _states = model.predict(obs, deterministic=True)
            step_result = env.step(action)
            
            # âœ… æ­£ç¡®å¤„ç†step()è¿”å›å€¼ - æ”¯æŒæ–°æ—§APIæ ¼å¼
            if len(step_result) == 5:
                obs, reward, terminated, truncated, info = step_result
                done = terminated or truncated
            else:
                obs, reward, done, info = step_result
                
            step_count += 1
            
            if step_count % 1000 == 0:
                current_balance = info.get('portfolio_value', 0)
                total_trades = info.get('total_trades', 0)
                print(f"ğŸ“Š æ­¥æ•°: {step_count:,}, å½“å‰èµ„äº§: ${current_balance:.2f}, æ€»äº¤æ˜“æ¬¡æ•°: {total_trades}")
        
        # è·å–å›æµ‹ç»“æœ
        trade_summary = env.get_trade_summary()
        
        print("\n" + "="*60)
        print("ğŸ“‹ å›æµ‹ç»“æœæ‘˜è¦:")
        print("="*60)
        
        # åŸºç¡€ç»Ÿè®¡
        print(f"ğŸ“ˆ æ€»æ”¶ç›Šç‡: {trade_summary.get('total_return', 0)*100:.2f}%")
        print(f"ğŸ’° æœ€ç»ˆèµ„äº§: ${trade_summary.get('final_balance', 0):.2f}")
        print(f"ğŸ“Š æ€»äº¤æ˜“æ¬¡æ•°: {trade_summary.get('total_trades', 0)}")
        print(f"ğŸ¯ èƒœç‡: {trade_summary.get('win_rate', 0)*100:.2f}%")
        print(f"ğŸ“‰ æœ€å¤§å›æ’¤: {trade_summary.get('max_drawdown', 0)*100:.2f}%")
        print(f"ğŸ“ å¤æ™®æ¯”ç‡: {trade_summary.get('sharpe_ratio', 0):.3f}")
        print(f"âš–ï¸  ç›ˆäºæ¯”: {trade_summary.get('profit_factor', 0):.2f}")
        
        # æ•°æ®æ¥æºè¯´æ˜
        print(f"\nğŸ” å›æµ‹æ•°æ®ä¿¡æ¯:")
        if os.path.exists(test_data_path):
            print("âœ… ä½¿ç”¨ç‹¬ç«‹æµ‹è¯•æ•°æ®é›† - æ— æ•°æ®æ³„éœ²é£é™©")
        else:
            print("âš ï¸  ä½¿ç”¨å®Œæ•´æ•°æ®é›† - å¯èƒ½åŒ…å«è®­ç»ƒæ•°æ®")
        
        print(f"ğŸ“… å›æµ‹æ—¶é—´èŒƒå›´: {df.index.min()} åˆ° {df.index.max()}")
        print(f"ğŸ“Š å›æµ‹æ•°æ®é‡: {len(df):,} æ¡è®°å½•")
        
        # åˆ›å»ºå¯è§†åŒ–åˆ†æ
        print(f"\nğŸ¨ ç”Ÿæˆå¯è§†åŒ–åˆ†ææŠ¥å‘Š...")
        try:
            from analysis.trading_visualizer import TradingVisualizer
            
            visualizer = TradingVisualizer()
            
            # è·å–äº¤æ˜“å†å²å’Œç»„åˆä»·å€¼å†å²
            trade_history = env.trade_history
            portfolio_history = env.portfolio_history
            
            # ç”Ÿæˆå›æµ‹åˆ†æå›¾è¡¨
            chart_path = visualizer.create_backtest_analysis_chart(
                df=df,
                trade_history=trade_history,
                portfolio_history=portfolio_history
            )
            
            if chart_path:
                print(f"ğŸ“Š å¯è§†åŒ–æŠ¥å‘Šå·²ç”Ÿæˆ: {chart_path}")
                print("ğŸŒ è¯·ç”¨æµè§ˆå™¨æ‰“å¼€HTMLæ–‡ä»¶æŸ¥çœ‹è¯¦ç»†åˆ†æ")
            
            # ç”Ÿæˆæ€§èƒ½åˆ†æå›¾è¡¨
            performance_chart = visualizer.create_performance_analysis_chart(trade_summary)
            if performance_chart:
                print(f"ğŸ“ˆ æ€§èƒ½åˆ†æå›¾è¡¨: {performance_chart}")
            
        except Exception as e:
            print(f"âš ï¸  å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
        
        print("="*60)
        return trade_summary
        
    except Exception as e:
        print(f"âŒ å›æµ‹å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None

def live_trading():
    """å®æ—¶äº¤æ˜“æ¨¡å¼"""
    print("ğŸ”´ å®æ—¶äº¤æ˜“æ¨¡å¼")
    print("ğŸ’¡ è¿™ä¸ªåŠŸèƒ½éœ€è¦è¿æ¥å®é™…çš„äº¤æ˜“æ‰€API")
    print("ğŸ“ å»ºè®®å…ˆåœ¨æ¨¡æ‹Ÿç¯å¢ƒä¸­å……åˆ†æµ‹è¯•ç­–ç•¥")
    
    # å¯ä»¥åœ¨è¿™é‡Œé›†æˆ deployment/live_trader.py
    try:
        from deployment.live_trader import LiveTrader
        print("âœ… å®æ—¶äº¤æ˜“æ¨¡å—å¯ç”¨")
        print("ğŸ“‹ ä½¿ç”¨æ–¹æ³•:")
        print("   1. é…ç½®APIå¯†é’¥")
        print("   2. è®¾ç½®é£é™©å‚æ•°")
        print("   3. å¯åŠ¨å®æ—¶äº¤æ˜“")
    except ImportError:
        print("âš ï¸ å®æ—¶äº¤æ˜“æ¨¡å—æœªå®‰è£…")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='SOL/USDTä¸­é¢‘åˆçº¦äº¤æ˜“ç­–ç•¥ - ä¼˜åŒ–ç‰ˆ')
    parser.add_argument('--mode', type=str, choices=['collect', 'train', 'backtest', 'live'], 
                       default='collect', help='è¿è¡Œæ¨¡å¼')
    parser.add_argument('--model-path', type=str, help='æ¨¡å‹è·¯å¾„ï¼ˆç”¨äºå›æµ‹ï¼‰')
    parser.add_argument('--force-refresh', action='store_true', help='å¼ºåˆ¶åˆ·æ–°ç¼“å­˜')
    
    args = parser.parse_args()
    
    # è®¾ç½®ç¯å¢ƒ
    setup_directories()
    
    # åˆå§‹åŒ–æ—¥å¿—
    logger = get_logger('Main', 'main.log')
    logger.info(f"å¯åŠ¨ SOL/USDT äº¤æ˜“ç­–ç•¥ - æ¨¡å¼: {args.mode}")
    
    print("ğŸš€ SOL/USDT ä¸­é¢‘åˆçº¦äº¤æ˜“ç­–ç•¥ - ä¼˜åŒ–ç‰ˆ")
    print("=" * 60)
    print(f"ğŸ¯ è¿è¡Œæ¨¡å¼: {args.mode}")
    if args.force_refresh:
        print("ğŸ”„ å¼ºåˆ¶åˆ·æ–°ç¼“å­˜")
    
    try:
        start_time = time.time()
        
        if args.mode == 'collect':
            collect_data()
            
        elif args.mode == 'train':
            # å…ˆæ”¶é›†æ•°æ®
            df = collect_data()
            if df is not None:
                model_path = train_model(df)
                if model_path:
                    print(f"\nğŸ‰ è®­ç»ƒæˆåŠŸå®Œæˆï¼")
                    print(f"ğŸ’¾ æ¨¡å‹ä¿å­˜åœ¨: {model_path}")
                    print(f"ğŸ“Š å¯åŠ¨TensorBoard: tensorboard --logdir=logs/tensorboard/")
            
        elif args.mode == 'backtest':
            results = backtest_model(model_path=args.model_path)
            if results:
                print(f"\nğŸ‰ å›æµ‹æˆåŠŸå®Œæˆï¼")
                print(f"ğŸ“Š æŸ¥çœ‹ç»“æœå›¾è¡¨äº†è§£è¯¦ç»†åˆ†æ")
            
        elif args.mode == 'live':
            live_trading()
        
        end_time = time.time()
        duration = end_time - start_time
        print(f"\nâ±ï¸  æ€»è€—æ—¶: {duration:.2f}ç§’")
            
    except KeyboardInterrupt:
        print("\nâš ï¸ ç¨‹åºè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.exception(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        print(f"âŒ ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
    
    print("\nğŸ‘‹ ç¨‹åºç»“æŸ")

if __name__ == "__main__":
    main() 